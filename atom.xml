<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Eric笔记</title>
  
  <subtitle>Eric笔记</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.yppcat.top/"/>
  <updated>2023-02-19T14:16:05.270Z</updated>
  <id>http://www.yppcat.top/</id>
  
  <author>
    <name>Eric笔记</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>函数指针与指针函数</title>
    <link href="http://www.yppcat.top/2023/02/19/%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E4%B8%8E%E6%8C%87%E9%92%88%E5%87%BD%E6%95%B0/"/>
    <id>http://www.yppcat.top/2023/02/19/函数指针与指针函数/</id>
    <published>2023-02-19T14:06:25.000Z</published>
    <updated>2023-02-19T14:16:05.270Z</updated>
    
    <content type="html"><![CDATA[<p><strong>函数调用的内存中的三个区域</strong></p><p>1.<strong>代码区</strong><br>    代码区装载了这个程序所对应的机器指令<br>    程序的执行就靠这些指令来驱动<br>2.<strong>静态数据区</strong><br>    装载了全局变量的数值<br>    后面程序的执行会改变这里的值<br>3.<strong>动态数据区</strong><br>    初始什么都没有，因为只有程序执行后，在指令的驱动下，这个区域才会产生数据。<br>    压栈、清栈的工作就是在这个区域完成的。</p><p><strong>CPU的三个寄存器</strong></p><p>1.eip<br>    代码区装载了这个程序所对应的机器指令<br>    程序的执行就靠这些指令来驱动<br>2.ebp<br>    装载了全局变量的数值<br>    后面程序的执行会改变这里的值<br>3.esp<br>    初始什么都没有，因为只有程序执行后，在指令的驱动下，这个区域才会产生数据。<br>    压栈、清栈的工作就是在这个区域完成的。</p><p><strong>指针函数概念（返回值）</strong></p><p>指针函数是 返回指针的函数 主体是函数，返回值是一个指针</p><p>int<em> fun(int,int);  //更加直观，返回值是int</em> 类型<br>int <em> fun(int,int);<br>int </em>fun(int,int);</p><p>在实现一个指针函数时，应该特别注意，指针函数返回的地址，在主调函数中，必须是有效的，是可以访问的内存。在上面程序中，str是函数内部的局部数组，局部变量分配在堆栈中，当函数执行完后，局部变量自动释放，在主调函数中，不能再访问，因此会有警告。访问一段释放的内存，是非法操作，显示的是0地址，若修改非法内存中的值，程序的后果可能更严重，是不可预料的</p><img src="/2023/02/19/函数指针与指针函数/image-20230219220902034.png" title="[函数指针与指针函数]"><p><strong>系统指针函数举例</strong></p><p>字符串拷贝函数</p><img src="/2023/02/19/函数指针与指针函数/image-20230219220956179.png" title="[函数指针与指针函数]"><p>字符串连接函数</p><img src="/2023/02/19/函数指针与指针函数/image-20230219221018602.png" title="[函数指针与指针函数]"><p><strong>函数指针</strong></p><p>函数指针是专门用来存放函数地址的指针，函数地址是一个函数的入口地址，函数名代表了函数的入口地址。</p><p>当一个函数指针指向了一个函数，就可以通过这个指针来调用该函数，可以将函数作为参数传递给函数指针</p><p><strong>声明形式</strong></p><p>&lt;数据类型&gt; （*&lt;函数指针名称&gt;)（&lt;参数说明列表&gt;)；</p><p>&lt;数据类型&gt;是函数指针所指向的函数的返回值类型；<br>&lt;函数指针名称&gt;符合标识符命名规则；<br>&lt;参数说明列表&gt;应该与函数指针所指向的函数的形参说明保持一致；<br>（<em>&lt;函数指针名称&gt;）中，</em>说明为指针，（）不可缺省，表明为指向函数的指针。</p><p>例子：int (<em>fun) (int);<br>注意 </em> 和函数名要用括号括起来，否则因为运算符的优先级原因就变成指针函数了</p><p>案例</p><img src="/2023/02/19/函数指针与指针函数/image-20230219221113636.png" title="[函数指针与指针函数]"><img src="/2023/02/19/函数指针与指针函数/image-20230219221121051.png" title="[函数指针与指针函数]"><p><strong>定义函数指针类型</strong></p><p>有时为了书写方便，可以声明一个函数指针数据类型<br>在函数指针变量说明前面，加上typedef，就变成了函数指针类型。<br>typedef &lt;数据类型&gt; （*&lt;函数指针类型名称&gt;)（&lt;参数说明列表&gt;)；</p><p>typedef int (*MFunc)(int, int);</p><p>int test(int a, int b, MFunc pFunc);<br>int plus(int a, int b); //函数声明<br>int minus(int, int);    //函数声明，缺省形参名称</p><p><strong>函数指针数组</strong></p><p>函数指针数组是一个包含若干个函数指针变量的数组。</p><p>&lt;数据类型&gt; ( * &lt;函数指针数组名称&gt; [&lt;大小&gt;] ) ( &lt;参数说明列表&gt; )；<br>&lt;大小&gt;是指函数指针数组元素的个数。</p><img src="/2023/02/19/函数指针与指针函数/image-20230219221229840.png" title="[函数指针与指针函数]"><p><strong>函数指针程序举例</strong></p><img src="/2023/02/19/函数指针与指针函数/image-20230219221245616.png" title="[函数指针与指针函数]"><p><strong>函数回调</strong></p><p>本质上就是一个函数指针的应用场景而已</p><p>回调函数主要结构有三部分组成：主函数、调用函数和被调函数，主要核心目的值在为了完成某个功能之后给与消息通知，或者是功能触发</p><p>因为可以把调用者与被调用者分开。调用者不关心谁是被调用者，所有它需知道的，只是存在一个具有某种特定原型、某些限制条件（如返回值为int）的被调用函数</p><p>如果想知道回调函数在实际中有什么作用，先假设有这样一种情况，我们要编写一个库，它提供了某些排序算法的实现，如冒泡排序、快速排序、归并排序等等，但为使库更加通用，不想在函数中嵌入排序逻辑，而让使用者来实现相应的逻辑；或者，想让库可用于多种数据类型（int、float、string），此时，该怎么办呢？可以使用函数指针，并进行回调</p><p>回调函数的优点</p><p>可以让实现方，根据回调方的多种形态进行不同的处理和操作。</p><p>可以让实现方，根据自己的需要定制回调方的不同形态。</p><p>可以将耗时的操作隐藏在回调方，不影响实现方其它信息的展示。</p><p>让代码的逻辑更加集中，更加易读。</p><p><strong>总结</strong></p><p>1.函数返回值返回是由条件的</p><p>2.函数的参数传递，数组条件下会有降级问题出现</p><p>3.函数实际上是有执行地址的</p><p>4.回调函数就是函数指针的一种应用</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;函数调用的内存中的三个区域&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.&lt;strong&gt;代码区&lt;/strong&gt;&lt;br&gt;    代码区装载了这个程序所对应的机器指令&lt;br&gt;    程序的执行就靠这些指令来驱动&lt;br&gt;2.&lt;strong&gt;静态数据区&lt;/strong&gt;&lt;
      
    
    </summary>
    
    
      <category term="C++学习笔记" scheme="http://www.yppcat.top/tags/C-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>指针详解</title>
    <link href="http://www.yppcat.top/2023/02/19/%E6%8C%87%E9%92%88%E8%AF%A6%E8%A7%A3/"/>
    <id>http://www.yppcat.top/2023/02/19/指针详解/</id>
    <published>2023-02-19T12:23:26.000Z</published>
    <updated>2023-02-19T12:34:07.823Z</updated>
    
    <content type="html"><![CDATA[<p><strong>什么是指针</strong></p><p>1.C语言中指针是一种数据类型，指针是存放数据的内存单元地址。<br>2.计算机系统的内存拥有大量的存储单元，每个存储单元的大小为1字节，为了便于管理，必须为每个存储单元编号，该编号就是存储单元的“地址”，每个存储单元拥有一个唯一的地址！<br>3.为了方便对于这些地址进行管理， C推出了专门对于地址的管理体系， 就是所谓的指针，这里一个指针代表的是一个地址， 同时当前地址可以被进行操作</p><p><strong>指针、地址、内存</strong></p><img src="/2023/02/19/指针详解/image-20230219202516138.png" title="[指针详解]"><p><strong>指针变量</strong></p><p>1.格式： 数据类型符 *指针变量名[=初始地址值]。</p><p>2.功能及目的：用来承接地址且提供运算依据</p><p><strong>变量指针</strong></p><p>指的是一个变量的地址</p><p><strong>取地址符号 &amp;</strong>  </p><p>取地址运算符“&amp;”的功能是取变量的地址，它是单目运算符。取地址运算符的运算对象必须是已经定义的变量或数组元素，但不能是数组名。运算结果是运算对象的地址</p><p><strong>指针运算符 *</strong></p><p>指针运算符“*”的功能是取指针变量所指向地址中的内容，与取地址运算符“&amp;”的运算是互逆的，它是单目运算符。指针运算符的运算对象必须是地址，可以是已赋值的指针变量，也可以是变量或数组元素的地址，但不能是整数，也不能是非地址型的变量。运算结果就是地址对应的变量。</p><img src="/2023/02/19/指针详解/image-20230219202718285.png" title="[指针详解]"><p><strong>运算符的支撑</strong></p><p>指针变量 ± 整数；</p><p>指针变量++ 与 ++指针变量；</p><p>指针变量– 与 –指针变量；</p><p>指针变量1- 指针变量2；</p><img src="/2023/02/19/指针详解/image-20230219202748768.png" title="[指针详解]"><p>案例</p><img src="/2023/02/19/指针详解/image-20230219202811744.png" title="[指针详解]"><p><strong>指针比较</strong></p><p>&lt;, &lt;=, ==, &gt;, &gt;=, !=都可以对指针做比较</p><p>比较它们在内存中的地址，数组中的单元的地址肯定是线性递增的</p><p><strong>0地址</strong></p><p>当然你的内存中有0地址，但是0地址通常是个不能随便碰的地址</p><p>因此可以用0地址来表示特殊的事情：<br>    返回的指针是无效的<br>    指针没有被真正初始化（先初始化为0）</p><p>NULL是一个预定义的符号，表示0地址</p><p><strong>异常指针</strong></p><p>空悬指针：<br>    指针正常初始化，曾指向过一个正常的对象，但是对象销毁了，该指针未置空，就成了悬空指针</p><p>野指针：<br>    未初始化的指针，其指针内容为一个垃圾数。 （一般我们定义一个指针时会初始化为NULL或者直接指向所要指向的变量地址，但是如果我们没有指向NULL或者变量地址就对指针进行使用，则指针指向的内存地址是随机的）。存在野指针是一个严重的错误</p><p>NULL指针分配的分区：其范围是从 0x00000000到0x0000FFFF。这段空间是空闲的，对于空闲的空间而言，没有相应的物理存储器与之相对应，所以对这段空间来说，任何读写操作都是会引起异常的。空指针是程序无论在何时都没有物理存储器与之对应的地址。为了保障“无论何时”这个条件，需要人为划分一个空指针的区域，固有上面NULL指针分区。</p><p><strong>堆空间内存分配问题</strong></p><p>目的：在程序运行过程中按需要自由分配所需空间；</p><p>malloc：在内存的动态存储器（堆区）中分配一块长度为size字节的连续内存空间，用来存放类型说明符指定的数据类型</p><p>free：free函数释放ptr指向的内存</p><img src="/2023/02/19/指针详解/image-20230219203034457.png" title="[指针详解]"><img src="/2023/02/19/指针详解/image-20230219203054118.png" title="[指针详解]">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;什么是指针&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.C语言中指针是一种数据类型，指针是存放数据的内存单元地址。&lt;br&gt;2.计算机系统的内存拥有大量的存储单元，每个存储单元的大小为1字节，为了便于管理，必须为每个存储单元编号，该编号就是存储单元的“地址”，每个存储
      
    
    </summary>
    
    
      <category term="C++学习笔记" scheme="http://www.yppcat.top/tags/C-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>C与JAVA的差异化对比与内存分配</title>
    <link href="http://www.yppcat.top/2023/02/19/C%E4%B8%8EJAVA%E7%9A%84%E5%B7%AE%E5%BC%82%E5%8C%96%E5%AF%B9%E6%AF%94%E4%B8%8E%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/"/>
    <id>http://www.yppcat.top/2023/02/19/C与JAVA的差异化对比与内存分配/</id>
    <published>2023-02-19T06:28:18.000Z</published>
    <updated>2023-02-19T06:42:31.017Z</updated>
    
    <content type="html"><![CDATA[<p><strong>数据存储原理与内存管理</strong></p><p><strong>JVM &amp; GCC</strong></p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143013644.png" title="[C与JAVA的差异化对比与内存分配]"><p><strong>JAVA 是 C 的一次封装</strong></p><p><strong>JAVA具有自动内存管理特性</strong></p><p><strong>C需要手动管理内存</strong></p><p><strong>JAVA额外开发了一组内存回收机制并且对内存做了限制</strong></p><p><strong>C是开放式，需要自己去处理</strong></p><p><strong>信号传输与总线概念</strong></p><p>信息传输依赖于电的正负极<br>传输介质是线<br>主板上的特殊花纹实际上是嵌入在主板上的线<br>也有我们日常认知的线</p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143147664.png" title="[C与JAVA的差异化对比与内存分配]"><p><strong>总线概念</strong></p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143217358.png" title="[C与JAVA的差异化对比与内存分配]"><p>这块板子上的花纹实际上是一些线路，用来传输电信号的<br>实际上在板子上得所有用来传输数据的线都可以称之为总线<br>但是根据传输数据的不同（使用意义不同），给与了不同的名字</p><p><strong>数据总线(Data Bus)</strong>：在CPU与RAM之间来回传送需要处理或是需要储存的数据。<br><strong>地址总线(Address Bus)</strong>：用来指定在RAM(Random Access Memory)之中储存的数据的地址。<br><strong>控制总线(Control Bus)</strong>：将微处理器控制单元(Control Unit)的信号，传送到周边设备，一般常见的为 USB Bus和1394<br><strong>扩展总线(Expansion Bus)</strong>：可连接扩展槽和电脑。<br><strong>局部总线(Local Bus</strong>)：取代更高速数据传输的扩展总线。</p><p>地址总线是一个单向数据传输，主要作用是去定位数据偏移量</p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143424369.png" title="[C与JAVA的差异化对比与内存分配]"><p>数据总线的主要作用是用来传输数据，他是一根双向线</p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143442888.png" title="[C与JAVA的差异化对比与内存分配]"><p><strong>地址概念</strong></p><p>想象：内存会将1个bit 作为一个数据保存点，内存由无数个点构成</p><p>内存将8个bit存储点进行一次编号，这个号码就是地址</p><p>地址总线的主要作用是传输地址数据过去，由内存条进行偏移量设置</p><p>数据总线的主要作用是从偏移量位置开始传递数据</p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143521892.png" title="[C与JAVA的差异化对比与内存分配]"><p><strong>指针</strong></p><p>从上面的处理过程可以看出来，CPU每次需要给如一个地址进行定位</p><p>那么意味着每一个变量数据都要有一个地址对应位置才能提取到！</p><p><strong>C语言的指针</strong></p><p>相C对比与JAVA他多出了一组特殊的变量，也就是指针变量。</p><p>他的目的是让我们能够自己去控制对应变量的存储位置</p><p>指针是一种数据类型，占用内存空间，用来保存内存地址</p><p><strong>JAVA中指针的概念</strong></p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143606613.png" title="[C与JAVA的差异化对比与内存分配]"><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143613883.png" title="[C与JAVA的差异化对比与内存分配]"><p><strong>JVM对于内存的应用</strong></p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143641923.png" title="[C与JAVA的差异化对比与内存分配]"><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143659526.png" title="[C与JAVA的差异化对比与内存分配]"><p><strong>C对于内存的应用</strong></p><img src="/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143717182.png" title="[C与JAVA的差异化对比与内存分配]">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;数据存储原理与内存管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;JVM &amp;amp; GCC&lt;/strong&gt;&lt;/p&gt;
&lt;img src=&quot;/2023/02/19/C与JAVA的差异化对比与内存分配/image-20230219143013644.pn
      
    
    </summary>
    
    
      <category term="C++学习笔记" scheme="http://www.yppcat.top/tags/C-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>binder分析</title>
    <link href="http://www.yppcat.top/2023/02/12/binder%E5%88%86%E6%9E%90/"/>
    <id>http://www.yppcat.top/2023/02/12/binder分析/</id>
    <published>2023-02-12T14:41:34.000Z</published>
    <updated>2023-02-12T14:41:34.897Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Binder-内存管理单元</title>
    <link href="http://www.yppcat.top/2023/02/08/Binder-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%8D%95%E5%85%83/"/>
    <id>http://www.yppcat.top/2023/02/08/Binder-内存管理单元/</id>
    <published>2023-02-08T00:27:44.000Z</published>
    <updated>2023-02-08T00:39:13.882Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-1-什么是MMU"><a href="#1-1-什么是MMU" class="headerlink" title="1.1 什么是MMU"></a>1.1 什么是MMU</h4><p>​        MMU(Memory Management Unit)主要用来<strong>管理虚拟存储器</strong>、物理存储器的控制线路，同时也负责虚拟地址映射为物理地址，以及提供硬件机制的内存访问授权、多任务多进程操作系统。</p><h4 id="1-2-发展历史"><a href="#1-2-发展历史" class="headerlink" title="1.2 发展历史"></a>1.2 发展历史</h4><blockquote><p>注意：学习一个知识点</p><p>很重要的一步是了解其为什么而存在？</p><p>它的存在是为了解决什么问题？</p><p>最后，在学习的过程中带着这些问题去理解、去思考</p></blockquote><p>​        在许多年以前，还是使用DOS或一些古老的操作系统时，内存很小，同时，应用程序也很小，将程序存储在内存中基本能够满足需要。随着科技的发展，图形界面及一些其他更复杂的应用出现，内存已经无法存储这些应用程序了，通常的解决办法是将程序分割成很多个<strong>覆盖块</strong>，覆盖块0最先运行，运行结束之后，就调用另一个覆盖块，虽然这些操作由OS来完成，</p><p>​        但是，需要程序员对程序进行分割，这非常不高效；因此，人们想出了一个<strong>虚拟存储器（virtual memory）</strong>的方法。</p><p>​    虚拟存储器的基本思想是：<strong>程序、数据、堆栈的总大小可以超过内存空间的大小，</strong></p><p>​    操作系统将当前运行的部分保存在内存中，未使用的部分保存在磁盘中。</p><p>​    比如一个<strong>16MB的程序</strong>和一个<strong>内存只有4MB</strong>的机器，操作系统通过选择可以决定哪部分4MB的程序内容保存在内存中，并在需要时，在内存与磁盘中交换程序代码，</p><p>这样16MB的代码就可以运行在4MB的机器中了</p><img src="/2023/02/08/Binder-内存管理单元/4.png" title="[Binder-内存管理单元]"><h4 id="1-2-相关概念"><a href="#1-2-相关概念" class="headerlink" title="1.2 相关概念"></a>1.2 相关概念</h4><p><strong>地址范围、虚拟地址映射成物理地址</strong>以及<strong>分页机制</strong></p><ul><li><p><strong>地址范围</strong>： 指处理器能够产生的地址集合，如一个32bit的处理器，其能产生的地址集合是<strong>0x0000 0000 ~ 0xffff ffff</strong>(4G)，这个地址范围也称为<strong>虚拟地址空间</strong>，其中对应的地址为<strong>虚拟地址</strong>。</p></li><li><p><strong>虚拟地址与物理地址</strong>： 与虚拟地址空间和虚拟地址相对应的是物理地址空间和物理地址；物理地址空间只是虚拟地址空间的一个<strong>子集</strong>。如一台内存为256MB的32bit主机，其虚拟地址空间是0 ~ 0xffffffff(4GB)，</p></li><li><p><strong>物理地址空间</strong>范围是0 ~ 0x0fff ffff(256M)</p></li></ul><h4 id="1-3分页机制"><a href="#1-3分页机制" class="headerlink" title="1.3分页机制"></a>1.3分页机制</h4><ul><li><p>如果处理器没有MMU，或者有MMU但没有启用，CPU执行单元发出的内存地址将直接传到芯片引脚上，被内存芯片（以下称为物理内存，以便与虚拟内存区分）接收，这称为物理地址（<strong>Physical Address</strong>，以下简称<strong>PA</strong>），如下图3-1-1所示；</p><img src="/2023/02/08/Binder-内存管理单元/2310756-67a4ff2b53385008.png" title="[Binder-内存管理单元]"><p>​        如果处理器启用了MMU，CPU执行单元发出的内存地址将被MMU截获，从CPU到MMU的地址称为虚拟，而MMU将这个地址翻译成另一个地址发到CPU芯片的外部地址引脚上，也就是将VA映射成PA，，如下图3-1-2。</p><img src="/2023/02/08/Binder-内存管理单元/2310756-3b1e7fc263f0642a.png" title="[Binder-内存管理单元]"><pre><code>linux使用MMU的机器都采用**分页机制**。虚拟地址空间以**页**为单位进行划分，而相应的物理地址空间也被划分，其使用的单位称为**页帧**，页帧和页必须保持相同，因为**内存与外部存储器之间的传输是以页为单位进行传输的**。</code></pre><p>​          例如，MMU可以通过一个映射项将VA的一页0xb70010000xb7001fff映射到PA的一页0x20000x2fff，如果CPU执行单元要访问虚拟地址0xb7001008，则实际访问到的物理地址是0x2008。</p><p>​        虚拟内存的哪个页面映射到物理内存的哪个页帧是通过<strong>页表（Page Table）</strong>来描述的，页表保存在<strong>物理内存中</strong>，<strong>MMU会查找页表来确定一个VA应该映射到什么PA。</strong></p></li></ul><h4 id="1-4页表的概念"><a href="#1-4页表的概念" class="headerlink" title="1.4页表的概念"></a>1.4页表的概念</h4><h5 id="1-4-1-CPU在执行指令与数据时，获得的是虚拟内存的地址。"><a href="#1-4-1-CPU在执行指令与数据时，获得的是虚拟内存的地址。" class="headerlink" title="1.4.1  CPU在执行指令与数据时，获得的是虚拟内存的地址。"></a>1.4.1  CPU在执行指令与数据时，获得的是虚拟内存的地址。</h5><p>​        但是CPU只能去物理内存寻址。此时，MMU就派上用场了。MMU负责，将虚拟地址，翻译成，真正运行时的物理地址。</p><p>MMU是如何将虚拟地址翻译成物理地址的，这个后面讲。现在先要了解一下交换区的概念。</p><blockquote><p><strong>交换区：</strong> 实际上就是一块磁盘空间（硬盘空间）。虚拟内存与物理内存映射的时候，是将虚拟内存的代码放到交换区中，以后在CPU想要执行相关的指令或者数据时，如果内存中没有，先去交换区将需要的指令与数据映射到物理内存，然后CPU再执行</p></blockquote><p>​        虚拟内存与交换取的这种概念，实现了大内存需求量的（多个）进程，能够（同时）运行在较小的物理内存中。如下图所示：</p><img src="/2023/02/08/Binder-内存管理单元/11.png" title="[Binder-内存管理单元]"><blockquote><p><strong>上图中，说的是进程的局部代码在物理内存中运行。是因为程序具有局部性原则，所以在某一段很小的时间段内，只有很少一部分代码会被CPU执行。</strong> </p></blockquote><p>​        到这里，我们应该大致明白了虚拟内存的作用与简单机制。还剩下MMU如何翻译虚拟地址为物理地址的，这放到最后讲解。现在先总结一下虚拟内存机制：</p><blockquote><p>虚拟内存需要重新映射到物理内存<br>虚拟地址映射到物理地址中的实际地址<br>每次只有进程的少部分代码会在物理内存中运行<br>大部分代码依然位于磁盘中（存储器硬盘）</p></blockquote><h5 id="1-4-2、-页式内存管理"><a href="#1-4-2、-页式内存管理" class="headerlink" title="1.4.2、 页式内存管理"></a>1.4.2、 页式内存管理</h5><p>上一节笼统的介绍了虚拟内存的概念。接下来学习内存管理中的一种方式：页式内存管理。<br>页式内存管理中我们需要了解：</p><blockquote><ul><li>页的概念</li><li>页表的概念</li><li>缺页的概念与页命中的概念</li><li>分配页面</li><li>程序的局部性原则</li></ul></blockquote><h5 id="1-4-2-页的概念"><a href="#1-4-2-页的概念" class="headerlink" title="1.4.2      页的概念"></a>1.4.2      页的概念</h5><pre><code>我们知道了**交换区**。我们知道交换区里面存放的是大部分的可执行代码与数据。而物理内存中，执行的是少部分的可执行代码与数据。</code></pre><p>那么此时就需要从交换区获取程序的代码，将它拿到物理内存执行。<strong>那么一次拿多少代码过来呢？这是一个问题！</strong></p><p>​        为了CPU的高效执行以及方便的内存管理，每次需要拿一个<strong>页的代码</strong>。这个页，指的是一段连续的存储空间（常见的是4Kb），也叫作块。</p><p>​        假设页的大小为P。在虚拟内存中，叫做<strong>虚拟页</strong>（VP）。从虚拟内存拿了一个页的代码要放到物理内存，那么自然物理内存也得有一个刚好一般大小的页才能存放虚拟页的代码。物理内存中的页叫做物理页（PP）</p><p>在任何时刻，虚拟页都是以下三种状态中的一种：</p><blockquote><ul><li>未分配的：VM系统还未分配的页（或者未创建）。未分配的页还没有任何数据与代码与他们相关联，因此也就不占用任何磁盘。</li><li>缓存的： 当前已缓存在物理内存中的已分配页</li><li>未缓存的：未缓存在物理内存中的已分配页</li></ul></blockquote><p>​        下图展示了一个8个虚拟页的小虚拟内存。其中：虚拟页0和3还没有被分配，因此在磁盘上还不存在。虚拟页1、4、 6被缓存在物理内存中。虚拟页2、 5、 7已经被分配，但是还没有缓存到物理内存中去执行。</p><img src="/2023/02/08/Binder-内存管理单元/12.png" title="[Binder-内存管理单元]"><h5 id="1-4-3-页表的概念"><a href="#1-4-3-页表的概念" class="headerlink" title="1.4.3 页表的概念"></a>1.4.3 页表的概念</h5><p>​        虚拟内存中的一些虚拟页是缓存在物理内存中被执行的。理所应当，应该有一种机制，来判断虚拟页，是否被缓存在了物理内存中的某个物理页上。如果不命中（需要一个页的代码，但是这个页未缓存在物理内存中），系统还必须知道这个虚拟页存放在磁盘上的哪个位置，从而在物理内存中选择一个空闲页或者替换一个牺牲页，并将需要的虚拟页从磁盘复制到物理内存中。</p><p>​        这些功能，是由软硬件结合完成的。 包括操作系统软件，MMU中的地址翻译硬件，和一个存放在物理内存中的页表的数据结构。</p><p>​        上一节说将<strong>虚拟页映射到物理页</strong>，实际上就是MMU地址翻译硬件将一个虚拟地址翻译成物理地址时，都会去读取页表的内容。操作系统负责维护页表的内容，以及在磁盘与物理内存之间来回传送页。</p><p><strong>下图是一个页表的基本组织结构</strong> </p><img src="/2023/02/08/Binder-内存管理单元/13.png" title="[Binder-内存管理单元]"><p>如上图所示：</p><p>​        页表实际上就是一个数组。这个数组存放的是一个称为页表条目（PTE）的结构。虚拟地址空间的每一个页在页表中，都有一个对应的页表条目（PTE）。虚拟页地址（首地址）翻译的时候就是查询的各个虚拟页在页表中的PTE，从而进行地址翻译的。</p><p>现在假设每一个PTE都有一个有效位和一个n位字段的地址。其中</p><blockquote><ul><li>有效位：表示对应的虚拟页是否缓存在了物理内存中。<strong>0表示未缓存。1表示已缓存</strong>。</li><li>n位地址字段：如果未缓存（有效字段为0），n位地址字段不为空的话，这个n位地址字段就表示该虚拟页在磁盘上的起始的位置。如果这个n位字段为空，那么就说明该虚拟页未分配。如果已缓存（有效字段为1），n位地址字段肯定不为空，它表示该虚拟页在物理内存中的起始地址。</li></ul></blockquote><p>​        综上分析，就得知，上图中：四个虚拟页VP1 , VP2, VP4 , VP7 是被缓存在物理内存中。 两个虚拟页VP0, VP5还未被分配。但是剩下的虚拟页VP3 ,VP6已经被分配了，但是还没有缓存到物理内存中去执行。</p><p>注意：任意的物理页，都可以缓存任意的虚拟页。（因为物理内存是全相联的）</p><h5 id="1-4-3-页命中"><a href="#1-4-3-页命中" class="headerlink" title="1.4.3  页命中"></a>1.4.3  页命中</h5><p>考虑下图的情形：</p><img src="/2023/02/08/Binder-内存管理单元/14.png" title="[Binder-内存管理单元]"><blockquote><p><strong>假设现在CPU想读取VP2页面中的某一个字节的内容。会发生什么呢？</strong></p></blockquote><p>​        当CPU得到一个地址vaddr想要访问它（这个addr就是上面想要访问的某一个字节的地址），</p><p>通过后面会学习的MMU地址翻译硬件，将虚拟地址addr作为索引定位到页表的PTE条目中的PTE2（这里假设是PTE2），</p><p>​        从内存中去读到PTE2的有效位为1，说明该虚拟页面已经被缓存了，所以CPU使用该PTE2条目中的物理内存地址（这个物理内存地址是PP1中的起始地址）构造出vaddr的物理地址paddr（这个地址是PP1页面起始地址或后面的某一个地址）。</p><p>​        然后CPU就会去paddr这个物理内存地址去取数据。这种情况，就是也命中。</p><p>实际上，上面的VP2的起始地址与paddr地址，很类似于内存的分段机制（X86以前就是</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-1-什么是MMU&quot;&gt;&lt;a href=&quot;#1-1-什么是MMU&quot; class=&quot;headerlink&quot; title=&quot;1.1 什么是MMU&quot;&gt;&lt;/a&gt;1.1 什么是MMU&lt;/h4&gt;&lt;p&gt;​        MMU(Memory Management Unit)主要
      
    
    </summary>
    
    
      <category term="binder" scheme="http://www.yppcat.top/tags/binder/"/>
    
  </entry>
  
  <entry>
    <title>Binder-为什么会有内核空间与用户空间</title>
    <link href="http://www.yppcat.top/2023/02/08/Binder-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%9C%89%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E4%B8%8E%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4/"/>
    <id>http://www.yppcat.top/2023/02/08/Binder-为什么会有内核空间与用户空间/</id>
    <published>2023-02-08T00:24:13.000Z</published>
    <updated>2023-02-08T00:32:31.502Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-1-简介-内存"><a href="#1-1-简介-内存" class="headerlink" title="1.1 简介 内存"></a>1.1 简介 内存</h4><blockquote><p>现代计算机都有两种以上的运行模式（普通模式、特权模式），</p><p>linux系统只有两层：</p><p>用户空间</p><ul><li>高优先级模式（特权模式）</li><li>低优先级模式（普通模式）。</li></ul></blockquote><p>​        linux系统在高优先级模式中运行系统<strong>内核代码</strong>以及与<strong>硬件密切</strong>相关的代码。<strong>低优先级</strong>运行<strong>应用程序</strong>与硬件无关部分。</p><p>​        应用程序不能<strong>直接操控硬件</strong>或者调用内核函数，需借助一系列接口函数申请让系统调用相关代码在内核空间运行，获取代码运行权限。</p><img src="/2023/02/08/Binder-为什么会有内核空间与用户空间/1.png" title="[Binder-为什么会有内核空间与用户空间]"><h5 id="1-2好处"><a href="#1-2好处" class="headerlink" title="1.2好处"></a>1.2好处</h5><ol><li><p>​        应用程序崩溃<strong>不会造成内核崩溃</strong>，拿windows举例来说，<strong>QQ崩溃掉不会造成程序死机</strong>。</p></li><li><p>​        每个应用程序或者进程都会有自己特定的地址、私有数据空间，<strong>程序之间一般不会相互影响</strong>        </p><p>​        例如QQ崩溃不会造成微信的崩溃。空间的隔离极大地提高了系统运行的稳定性。</p></li></ol><h5 id="1-3计算机蓝屏带来的启示"><a href="#1-3计算机蓝屏带来的启示" class="headerlink" title="1.3计算机蓝屏带来的启示"></a>1.3计算机蓝屏带来的启示</h5><p>​        计算机蓝屏主要是因为计算机<strong>硬件驱动不兼容</strong>问题造成，<strong>硬件驱动代码运行在内核空间</strong>，与kernel运行在相同空间内，所以驱动程序发生问题容易造成系统的崩溃。将用户空间与内核空间隔离开，可减少系统崩溃的可能，提高系统的稳定性。毕竟现实情况中，应用程序崩溃的情况比蓝屏出现的概率要多的多得多。在linux中这种情况可以类比。</p><p>​        window有上百个驱动，如蓝牙驱动，主板驱动，声卡驱动，麦克风驱动，显卡驱动，USB驱动等等！驱动过多容易造成蓝屏的出现。他们都运行在内核中。为什么会有这么多驱动。电脑中每一个配件都可以随意组合。形成一个完整的电脑</p><p>Android 发现</p><p>​        在Android系统中，虽然也是基于Linux系统，但是这些驱动在Android厂商都已经消失了。全部集成化了、除了Binder驱动外，屏幕驱动，蓝牙驱动外几乎看不到其他驱动，这也是蓝屏比较少的原因</p><h5 id="1-4-在linux中"><a href="#1-4-在linux中" class="headerlink" title="1.4 在linux中"></a>1.4 在linux中</h5><p>​        每一个系统进程都拥有自己私有的地址空间和数据，用户空间造成的进程错误会被局部化，而不会影响到内核或者其他进程。（上面所说QQ和微信的例子）。</p><p>​        当用户进程需要完成在特权模式下才能完成的某些工作时，通过linux向上提供的系统调用接口进入特权模式，然后执行调用所提供的有限功能<br>​        应用程序正常情况下都是运行在普通模式下，这部分代码运行的空间称为用户空间，当代码通过系统调用计入到特权级别运行的时候，对应的代码执行空间称为内核空间。</p><blockquote><p>linux系统中每个进程占有4G空间（虚拟空间，并不一定真实占用）</p></blockquote><p><strong>空间分布如下：</strong></p><ol><li>用户空间： 0~(3G-1) 普通的应用程序代码运行在此部分空间中</li><li>内核空间： 3G~(4G-1) 内核代码段，其中驱动就是运行在此部分空间中</li></ol><h5 id="1-5-用户空间与内核空间交流"><a href="#1-5-用户空间与内核空间交流" class="headerlink" title="1.5 用户空间与内核空间交流"></a>1.5 用户空间与内核空间交流</h5><p>​        用户空间应用程序往往需要调用硬件（QQ调用相机拍照）或者运行与系统核心相关的内容（360清理进程），免不了与内核打交道，他们之间调用关系又是怎样呢？</p><p>交流关系以open()文件打开函数为例<br>上层应用在用户空间执行到 open() API函数时，会触发系统软中断，系统调用 系统调用函数 sys_open()系统调用函数，在内核空间执行open代码，这样用户空间的open函数内部代码就取得了在内核空间运行的权限，可以做一些比较牛比较核心的事情。<br>应用层API函数还有很多，大约有250个左右，涵盖范围包括文件操作、进程控制、网络操作等等。调用原理大致相同。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-1-简介-内存&quot;&gt;&lt;a href=&quot;#1-1-简介-内存&quot; class=&quot;headerlink&quot; title=&quot;1.1 简介 内存&quot;&gt;&lt;/a&gt;1.1 简介 内存&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;现代计算机都有两种以上的运行模式（普通模式、特权模式），&lt;
      
    
    </summary>
    
    
      <category term="binder" scheme="http://www.yppcat.top/tags/binder/"/>
    
  </entry>
  
  <entry>
    <title>handler笔记</title>
    <link href="http://www.yppcat.top/2023/02/07/handler%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.yppcat.top/2023/02/07/handler笔记/</id>
    <published>2023-02-07T00:50:28.000Z</published>
    <updated>2023-02-07T01:14:07.596Z</updated>
    
    <content type="html"><![CDATA[<p><strong>用一句话概括Handler，并简述其原理</strong></p><p>Handler是Android系统的根本，在Android应用被启动的时候，会分配一个单独的虚拟机，虚拟机会执行ActivityThread中的main方法，在main方法中对主线程Looper进行了初始化，也就是几乎所有代码都执行在Handler内部。Handler也可以作为主线程和子线程通讯的桥梁。Handler通过sendMessage发送消息，将消息放入MessageQueue中，在MessageQueue中通过时间的维度来进行排序，Looper通过调用loop方法不断的从MessageQueue中获取消息，执行Handler的dispatchMessage，最后调用handleMessage方法。</p><p><strong>为什么系统不建议在子线程访问UI？（为什么不能在子线程更新UI？）</strong></p><p>在某些情况下，在子线程中是可以更新UI的。但是在ViewRootImpl中对UI操作进行了checkThread，但是我们在OnCreate和onResume中可以使用子线程更新UI，由于我们在ActivityThread中的performResumeActivity方法中通过addView创建了ViewRootImpl，这个行为是在onResume之后调用的，所以在OnCreate和onResume可以进行更新UI。</p><p>但是我们不能在子线程中更新UI，因为如果添加了耗时操作之后，一旦ViewRootImpl被创建将会抛出异常。一旦在子线程中更新UI，容易产生并发问题。</p><p><strong>一个Thread可以有几个Looper？几个Handler？</strong></p><p>一个线程只能有一个Looper，可以有多个Handler，在线程中我们需要调用Looper.perpare,他会创建一个Looper并且将Looper保存在ThreadLocal中，每个线程都有一个LocalThreadMap，会将Looper保存在对应线程中的LocalThreadMap，key为ThreadLocal，value为Looper</p><p><strong>可以在子线程直接new一个Handler吗？那该怎么做？</strong></p><p>可以在子线程中创建Handler，我们需要调用Looper.perpare和Looper.loop方法。或者通过获取主线程的looper来创建Handler</p><p><strong>Message可以如何创建？哪种效果更好，为什么？</strong></p><p>Message.obtain来创建Message。这样会复用之前的Message的内存，不会频繁的创建对象，导致内存抖动。</p><p><strong>主线程中Looper的轮询死循环为何没有阻塞主线程？</strong></p><p>Looper轮询是死循环，但是当没有消息的时候他会block，ANR是当我们处理点击事件的时候5s内没有响应，我们在处理点击事件的时候也是用的Handler，所以一定会有消息执行，并且ANR也会发送Handler消息，所以不会阻塞主线程。</p><p><strong>使用Hanlder的postDealy()后消息队列会发生什么变化？</strong></p><p>Handler发送消息到消息队列，消息队列是一个时间优先级队列，内部是一个单向链表。发动postDelay之后会将该消息进行时间排序存放到消息队列中</p><p><strong>点击页面上的按钮后更新TextView的内容，谈谈你的理解？</strong></p><p>点击按钮的时候会发送消息到Handler，但是为了保证优先执行，会加一个标记异步，同时会发送一个target为null的消息，这样在使用消息队列的next获取消息的时候，如果发现消息的target为null，那么会遍历消息队列将有异步标记的消息获取出来优先执行，执行完之后会将target为null的消息移除。(同步屏障)</p><p><strong>生产者-消费者设计模式懂不？</strong></p><p>举个例子，面包店厨师不断在制作面包，客人来了之后就购买面包，这就是一个典型的生产者消费者设计模式。但是需要注意的是如果消费者消费能力大于生产者，或者生产者生产能力大于消费者，需要一个限制，在java里有一个blockingQueue。当目前容器内没有东西的时候，消费者来消费的时候会被阻塞，当容器满了的时候也会被阻塞。Handler.sendMessage相当于一个生产者,MessageQueue相当于容器，Looper相当于消费者。</p><p><strong>Handler是如何完成子线程和主线程通信的？</strong></p><p>在主线程中创建Handler，在子线程中发送消息，放入到MessageQueue中,通过Looper.loop取出消息进行执行handleMessage，由于looper我们是在主线程初始化的，在初始化looper的时候会创建消息队列，所以消息是在主线程被执行的。</p><p><strong>关于ThreadLocal，谈谈你的理解？</strong></p><p>ThreadLocal类似于每个线程有一个单独的内存空间，不共享，ThreadLocal在set的时候会将数据存入对应线程的ThreadLocalMap中，key=ThreadLocal，value=值</p><p><strong>享元设计模式有用到吗？</strong></p><p>享元设计模式就是重复利用内存空间，减少对象的创建，Message中使用到了享元设计模式。内部维护了一个链表，并且最大长度是50，当消息处理完之后会将消息内的属性设置为空，并且插入到链表的头部，使用obtain创建的Message会从头部获取空的Message</p><p> <strong>Handler内存泄漏问题及解决方案</strong></p><p>内部类持有外部类的引用导致了内存泄漏，如果Activity退出的时候，MessageQueue中还有一个Message没有执行，这个Message持有了Handler的引用，而Handler持有了Activity的引用，导致Activity无法被回收，导致内存泄漏。使用static关键字修饰，在onDestory的时候将消息清除。</p><p> <strong>Handler异步消息处理（HandlerThread）</strong></p><p>内部使用了Handler+Thread，并且处理了getLooper的并发问题。如果获取Looper的时候发现Looper还没创建，则wait，等待looper创建了之后在notify</p><p><strong>子线程中维护的Looper，消息队列无消息的时候处理方案是什么？有什么用？</strong></p><p>子线程中创建了Looper，当没有消息的时候子线程将会被block，无法被回收，所以我们需要手动调用quit方法将消息删除并且唤醒looper，然后next方法返回null退出loop</p><p> <strong>既然可以存在多个Handler往MessageQueue中添加数据(发消息是各个handler可能处于不同线程)，那他内部是如何确保线程安全的？</strong></p><p>在添加数据和执行next的时候都加了this锁，这样可以保证添加的位置是正确的，获取的也会是最前面的。</p><p><strong>关于IntentService，谈谈你的理解</strong></p><p>HandlerThread+Service实现，可以实现Service在子线程中执行耗时操作，并且执行完耗时操作时候会将自己stop。</p><p><strong>Glide是如何维护生命周期的？ 一般想问的应该都是这里</strong></p><p><code>@NonNull</code></p><p><code>private RequestManagerFragment getRequestManagerFragment(</code></p><p><code>@NonNull final android.app.FragmentManager fm,</code></p><p><code>@Nullable android.app.Fragment parentHint,boolean isParentVisible) {</code></p><p><code>RequestManagerFragment current = (RequestManagerFragment)</code></p><p><code>fm.findFragmentByTag(FRAGMENT_TAG);</code></p><p><code>if (current == null) {</code></p><p><code>current = pendingRequestManagerFragments.get(fm);</code></p><p><code>if (current == null) {</code></p><p><code>current = new RequestManagerFragment();</code></p><p><code>current.setParentFragmentHint(parentHint);</code></p><p><code>if (isParentVisible) {</code></p><p><code>current.getGlideLifecycle().onStart();</code></p><p><code>}</code></p><p><code>pendingRequestManagerFragments.put(fm, current);</code></p><p><code>fm.beginTransaction().add(current,</code></p><p><code>FRAGMENT_TAG).commitAllowingStateLoss();</code></p><p><code>handler.obtainMessage(ID_REMOVE_FRAGMENT_MANAGER, fm).sendToTarget();</code></p><p><code>}</code></p><p><code>}</code></p><p><code>return current;</code></p><p><code>}</code></p><p>1.为什么会判断两次null，再多次调用with的时候，commitAllowingStateLoss会被执行两次，所以我们需要使用一个map集合来判断，如果map中已经有了证明已经添加过了</p><p>2.handler.obtainMessage(ID_REMOVE_FRAGMENT_MANAGER, fm).sendToTarget();我们需要将map里面的记录删除。</p><p><strong>Linux的epoll机制</strong></p><p><strong>epoll的通俗解释</strong></p><p>epoll的通俗解释是一种当文件描述符的内核缓冲区非空的时候，发出可读信号进行通知，当写缓冲区不满的时候，发出可写信号通知的机制</p><p>epoll的核心是3个API，核心数据结构是：1个红黑树和1个链表</p><p>epoll_create1 : 创建一个epoll实例，文件描述符</p><p>epoll_ctl : 将监听的文件描述符添加到epoll实例中，实例代码为将标准输入文件描述符添加到epoll中</p><p>epoll_wait : 等待epoll事件从epoll实例中发生， 并返回事件以及对应文件描述符</p><p><strong>epoll：</strong>采用回调机制。在执行epoll_ctl的add操作时，不仅<strong>将文件描述符放到红黑树上</strong>，而且也注册了回调函数，</p><p>内核在检测到某文件描述符可读/可写时会调用回调函数，该回调函数<strong>将文件描述符放在就绪链表中</strong>。</p><p><strong>epoll高效的本质在于：</strong></p><p>减少了用户态和内核态的文件句柄拷贝</p><p>减少了对可读可写文件句柄的遍历mmap 加速了内核与用户空间的信息传递，epoll是通过内核与用户mmap同一块内存，避免了无谓的内存拷贝</p><p>IO性能不会随着监听的文件描述的数量增长而下降</p><p>使用红黑树存储fd，以及对应的回调函数，其插入，查找，删除的性能不错，相比于hash，不必预先分配很多的空间</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;用一句话概括Handler，并简述其原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Handler是Android系统的根本，在Android应用被启动的时候，会分配一个单独的虚拟机，虚拟机会执行ActivityThread中的main方法，在main方法中对主线程L
      
    
    </summary>
    
    
      <category term="android" scheme="http://www.yppcat.top/tags/android/"/>
    
  </entry>
  
  <entry>
    <title>jetpack</title>
    <link href="http://www.yppcat.top/2022/12/28/jetpack/"/>
    <id>http://www.yppcat.top/2022/12/28/jetpack/</id>
    <published>2022-12-28T03:07:25.000Z</published>
    <updated>2022-12-28T03:13:12.879Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Lifecycle</strong></p><p>1.Activity实现了LifecycleOwner被观察者 addObserver添加观察者 map存入观察者<br>2.LiveData粘性事件是因为添加时当前的version和被观察者的version不一致导致，可通过反射hook的方式修改<br>3.Activity内部添加了ReportFragment来感知生命周期向观察者发送事件<br>4.Activity实现了状态机，能够顺序显示和退出 同事同步自己的状态给被观察者<br>5.LiveData观察者接收事件后再setValue会导致后续的观察者只能收到新的事件<br>6.postValue本质是切到主线程在setValue 回调在主线程</p><p><strong>ViewModel</strong></p><p>Boudle作为数据存储，就已经和当前Activity实例没有任何关系了！<br>存储手段， 表层应用的是一个Hashmap</p><p>不受Activity实例影响，<br>Bundle理解为进程中的共享数据区<br>Activity继承ComponentActivity在内部通过LifeCycle监听到onSaveInstanceState事件通过mSavedStateRegistryController.performSave(outState)将数据存入到Bundle中<br>内部通过LifeCycle监听到onDestroy事件通过getViewModelStore().clear()去清除Map中的数据，此处map中放的是ViewModel中的数据<br>销毁重建走onCreate通过mSavedStateRegistryController.performRestore(savedInstanceState)从Bundle中恢复数据<br>本质上是Bundle的上层封装，Bundle通过类名去查找数据<br>本质是两个Activity之间的数据传递，上一个被销毁的Activity与新建的这个Activity建立的Bundle数据传递</p><p><strong>WorkManager</strong></p><p>1.架构上使用JobServiceManager或AlarmService进行调用执行<br>2.数据传递上使用Database进行存储<br>3.执行角度上利用线程池提供具体的执行能力<br>4.编译完manifest会生成contentProvider 和receiver等</p><p>1.WorkManger最大的特色， 是不依赖于当前用户进程<br>    当前用户进行killed，任务能够继续执行<br>    保活！  绝对意义上的保活</p><p>2.WorkManager区别于Service提供了一系列的便于我们处理任务的业务<br>    任务链<br>    触发条件执行</p><p>WorkManager<br>    1.架构设计<br>        独立于当前APP进程，由第三方进行进行调用<br>    2.业务设计<br>        支持条件约束<br>        支持循环任务<br>        支持任务链</p><p>1.底层提供能力的是线程池</p><p>2.封装成了一个线性的队列执行</p><p>3.当前SDK版本&gt;23的情况下，是由jobservice提供调用支持</p><p>4.如果是小于23的情况下是AlarmService提供调用支持！</p><p>从创建角度上来将<br>        1.默认会生成CP  作为组件进行注册<br>            1.1. 构建一个线程池提供具体的执行能力<br>            1.2. 根据版本构建JSM 或AlarmService进行调用执行</p><pre><code>通过recevier支持各种约束环节！对应数据直接入了数据库在使用时，取数据库中的数据提取进行处理1.架构上用JSM 或AlarmService进行调用执行2.数据传递上用Database进行存储3.执行角度利用线程池提供具体执行能力能不能做保活？？各大手机厂商，对于ROM的系统，隔一段事件 直接一次性清除掉非系统进程的所有进程WorkManager这东西用不了！    有时候会失效，就是因为厂商做了处理ROM厂商定制    连JMS   ALARMSERVICE</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Lifecycle&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.Activity实现了LifecycleOwner被观察者 addObserver添加观察者 map存入观察者&lt;br&gt;2.LiveData粘性事件是因为添加时当前的version和被观察者的versio
      
    
    </summary>
    
    
      <category term="Jetpack" scheme="http://www.yppcat.top/tags/Jetpack/"/>
    
  </entry>
  
  <entry>
    <title>IO加解密核心与dex文件改造过程分析</title>
    <link href="http://www.yppcat.top/2022/12/06/IO%E5%8A%A0%E8%A7%A3%E5%AF%86%E6%A0%B8%E5%BF%83%E4%B8%8Edex%E6%96%87%E4%BB%B6%E6%94%B9%E9%80%A0%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90/"/>
    <id>http://www.yppcat.top/2022/12/06/IO加解密核心与dex文件改造过程分析/</id>
    <published>2022-12-06T12:33:42.000Z</published>
    <updated>2022-12-06T12:45:21.299Z</updated>
    
    <content type="html"><![CDATA[<p><strong>IO及序列化</strong></p><p>IO及序列化学习完成后，我能用用他们做什么？<br>数据的加解密<br>文件的读写<br>网络数据的传输</p><p><strong>加解密的核心原理</strong></p><p>加密原理其实很简单，通俗的说就是打乱所加密文件的内容，举个简单例子：你的桌面图标是不是可以按顺序排列，按时间排列，按大小排列，按内容排列？对的就是这个原理 加密就是打乱信息内容，比如把第一个字放在最后，在吧最后一个字放在前面，按照一定的算法，给一个自己编写的函数，比如递归加密，异或加密等等，解密的时候倒过来解密，异或加密，倒过来解密就是先或在异。 有的加密，把内容打乱后在进行2次整体加密。。完了后在加…… 其实不用加密软软件：我根据加密的原理自己手动加密，一个简单的方法。。你把文件后缀名改掉，比如JPG，改成CHM,log.WIN等等。。个人倾向改成系统问价后缀，然后把改了的文件在压缩，，压缩后在吧压缩文件后缀RAR在改掉、、，，恶心吧。。多改几次。。别人怎么能打开？当然你的指导顺序在改回来。。一般我是最后改成INF或者COM系统后缀放在C盘的系统问文件夹下面。。。一般别人也不会动、。</p><p><strong>数字签名-哈希散列</strong></p><p><strong>MD5算法:</strong><br>MD5 用的是 哈希函数，它的典型应用是对一段信息产生 信息摘要，以 防止被篡改。严格来说，MD5 不是一种 加密算法 而是 摘要算法。无论是多长的输入，MD5 都会输出长度为 128bits 的一个串 (通常用 16 进制 表示为 32 个字符)。。<br>对称加密和非对称加密<br>加密算法分 对称加密 和 非对称加密，其中对称加密算法的加密与解密 密钥相同，非对称加密算法的加密密钥与解密 密钥不同，此外，还有一类 不需要密钥 的 散列算法。</p><p><strong>SHA1算法：</strong><br>HA1 是和 MD5 一样流行的 消息摘要算法，然而 SHA1 比 MD5 的 安全性更强。对于长度小于 2 ^ 64 位的消息，SHA1 会产生一个 160 位的 消息摘要。基于 MD5、SHA1 的信息摘要特性以及 不可逆 (一般而言)，可以被应用在检查 文件完整性 以及 数字签名 等场景。</p><p><strong>对称加密与非对称加密</strong></p><p><strong>AES算法:</strong><br>AES 加密算法是密码学中的 高级加密标准，该加密算法采用 对称分组密码体制，密钥长度的最少支持为 128 位、 192 位、256 位，分组长度 128 位，算法应易于各种硬件和软件实现。这种加密算法是美国联邦政府采用的 区块加密标准。</p><p><strong>RSA算法：</strong><br>RSA 加密算法是目前最有影响力的 公钥加密算法，并且被普遍认为是目前 最优秀的公钥方案 之一。RSA 是第一个能同时用于 加密 和 数字签名 的算法，它能够 抵抗 到目前为止已知的 所有密码攻击，已被 ISO 推荐为公钥数据加密标准。</p><p><strong>ECC算法：</strong><br>ECC 也是一种 非对称加密算法，主要优势是在某些情况下，它比其他的方法使用 更小的密钥，比如 RSA 加密算法，提供 相当的或更高等级 的安全级别。不过一个缺点是 加密和解密操作 的实现比其他机制 时间长 (相比 RSA 算法，该算法对 CPU 消耗严重)。。</p><p><strong>各算法比较</strong></p><p><strong>散列</strong></p><img src="/2022/12/06/IO加解密核心与dex文件改造过程分析/image-20221206203731247.png" title="[IO加解密核心与dex文件改造过程分析]"><p><strong>对称加密算法</strong></p><img src="/2022/12/06/IO加解密核心与dex文件改造过程分析/image-20221206203753881.png" title="[IO加解密核心与dex文件改造过程分析]"><p><strong>非对称算法</strong></p><img src="/2022/12/06/IO加解密核心与dex文件改造过程分析/image-20221206203809988.png" title="[IO加解密核心与dex文件改造过程分析]"><p><strong>大厂中加密思想：算法自定义，数学与性能的考虑，CPU利用与汇编底层的融合</strong></p><h2 id="APK反编译原理及实战"><a href="#APK反编译原理及实战" class="headerlink" title="APK反编译原理及实战"></a><strong>APK反编译原理及实战</strong></h2><img src="/2022/12/06/IO加解密核心与dex文件改造过程分析/image-20221206203920035.png" title="[IO加解密核心与dex文件改造过程分析]"><img src="/2022/12/06/IO加解密核心与dex文件改造过程分析/image-20221206203911695.png" title="[IO加解密核心与dex文件改造过程分析]"><p><strong>加固的总体思想</strong></p><p>一个程序员的故事：<br>辛辛苦苦找到一个对象，婚后家里主权为大，老婆管钱，导致这程序员木有经费去做一些爱做的事情。然而这个程序员很努力，平时除了上班，还能够做点外包，赚点外快。 所以他就想到了把工资卡上交，而把赚到的外快放到了自己的小金库。从此过上了性福生活。<br>结果被你反手一掏，小金库没了，从此欲哭无泪。<br>钱 = 代码<br>金库 = 编译过程<br>反手一套 = 破解过程</p><p><strong>加固基本原理</strong></p><p><strong>Dex文件 是什么？</strong></p><p>加固的目的是保护dex，直接而言就是对dex文件进 行操作，对dex文件动刀子，必须知道dex文件是什 么，能否直接动刀子。什么是源dex？什么是壳dex？</p><p><strong>Apk打包 流程</strong></p><p>加壳是在原来apk的基础上加一层保护壳，dex文件 修改了就需要重新打包，否则apk安装不了。这就需 要我们详细学习apk如何打包的，</p><p><strong>Dex文件加 载流程</strong></p><p>加壳后的文件是不能直接用的，dex文件是加密的， 所以我们需要对他进行解密，解密后的dex文件如何 加载？</p><p><strong>APK加载流程</strong></p><img src="/2022/12/06/IO加解密核心与dex文件改造过程分析/image-20221206204129808.png" title="[IO加解密核心与dex文件改造过程分析]"><p><strong>加壳步骤</strong></p><p>1、制作原始项目的apk，这里称作original.apk；<br>2、制作一个壳项目（具体功能见ps），编译通过后得到它的classes.dex文件，这里称作shell.dex，而壳项目的apk称作shell.apk（需要签名）；<br>3、制作一个加壳工具（java工程就可以），按照以下流程工作：<br>1）读取original.apk的byte流，并加密；<br>2）读取shell.dex的byte流；<br>3）new一个新的byte数组，长度为1）和2）的长度之和+4，因为我们要在shell.dex中保存original.apk的长度；<br>4）在new byte数组中写入2），写入1），写入1）的长度；<br>5）根据dex文件的结构，修改checksum文件头、Signature文件头和file_size文件头，最终生成一个新的classes.dex；<br>4、替换掉2中的shell.apk中的classes.dex，并使用工具重新签名；<br>5、生成的新签名apk就是我们加壳过的apk了。</p><p><strong>脱壳流程</strong></p><img src="/2022/12/06/IO加解密核心与dex文件改造过程分析/image-20221206204213005.png" title="[IO加解密核心与dex文件改造过程分析]">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;IO及序列化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;IO及序列化学习完成后，我能用用他们做什么？&lt;br&gt;数据的加解密&lt;br&gt;文件的读写&lt;br&gt;网络数据的传输&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加解密的核心原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;加密原理其实很简单，通俗的
      
    
    </summary>
    
    
      <category term="IO" scheme="http://www.yppcat.top/tags/IO/"/>
    
  </entry>
  
  <entry>
    <title>序列化</title>
    <link href="http://www.yppcat.top/2022/12/06/%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>http://www.yppcat.top/2022/12/06/序列化/</id>
    <published>2022-12-06T02:50:54.000Z</published>
    <updated>2022-12-06T03:11:25.646Z</updated>
    
    <content type="html"><![CDATA[<p><strong>序列化定义以及相关概念</strong></p><p>由于在系统底层，数据的传输形式是简单的字节序列形式传递，即在底层，系统不认识对象，只认识字节序列，而为了达到进程通讯的目的，需要先将数据序列化，而序列化就是将对象转化字节序列的过程。相反地，当字节序列被运到相应的进程的时候，进程为了识别这些数据，就要将其反序列化，即把字节序列转化为对象</p><p>无论是在进程间通信、本地数据存储又或者是网络数据传输都离不开序列化的支持。而针对不同场景选择合适的序列化方案对于应用的性能有着极大的影响。</p><p>从广义上讲，数据序列化就是将数据结构或者是对象转换成我们可以存储或者传输的数据格式的一个过程，在序列化的过程中，数据结构或者对象将其状态信息写入到临时或者持久性的存储区中，而在对应的反序列化过程中，则可以说是生成的数据被还原成数据结构或对象的过程。</p><p>序列化本质上其实就是将数据结构或对象转换成二进制串的过程。<br>反序列化本质是将在序列化过程中所生成的二进制串转换成数据结构或者对象的过程</p><p><strong>数据结构、对象与二进制串</strong></p><p>不同的计算机语言中，数据结构，对象以及二进制串的表示方式并不相同。</p><p>数据结构和对象：对于类似 Java 这种完全面向对象的语言，工程师所操作的一切都是对象（Object），来自于类的实例化。在 Java 语言中最接近数据结构的概念，就是 POJO（Plain Old JavaObject）或者 Javabean－－那些只有 setter/getter 方法的类。而在 C 二进制串：序列化所生成的二进制串指的是存储在内存中的一块数据。C 语言的字符串可以直接被传输层使用，因为其本质上就是以’0’结尾的存储在内存中的二进制串。在 Java 语言里面，二进制串的概念容易和String 混淆。实际上String 是 Java 的一等公民，是一种特殊对象（Object）。对于跨语言间的通讯，序列化后的数据当然不能是某种语言的特殊数据类型。二进制串在 Java 里面所指的是 byte[]，byte 是 Java 的 8 中原生数据类型之一（Primitive data types）。</p><p><strong>序列化协议特性</strong></p><p><strong>通用性</strong><br>技术层面，序列化协议是否支持跨平台、跨语言。如果不支持，在技术层面上的通用性就大大降低了。<br>流行程度，序列化和反序列化需要多方参与，很少人使用的协议往往意味着昂贵的学习成本；另一方面，流行度低的协议，往往缺乏稳定而成熟的跨语言、跨平台的公共包。</p><p><strong>强健性 / 鲁棒性</strong><br>成熟度不够<br>语言 / 平台的不公平性</p><p><strong>可调试性 / 可读性</strong><br>支持不到位<br>访问限制</p><p><strong>性能</strong><br>性能包括两个方面，时间复杂度和空间复杂度。<br>空间开销（Verbosity）， 序列化需要在原有的数据上加上描述字段，以为反序列化解析之用。如果序列化过程引入的额外开销过高，可能会导致过大的网络，磁盘等各方面的压力。对于海量分布式存储系统，数据量往往以 TB 为单位，巨大的的额外空间开销意味着高昂的成本。<br>时间开销（Complexity），复杂的序列化协议会导致较长的解析时间，这可能会使得序列化和反序列化阶段成为整个系统的瓶颈。</p><p><strong>可扩展性 / 兼容性</strong><br>移动互联时代，业务系统需求的更新周期变得更快，新的需求不断涌现，而老的系统还是需要继续维护。如果序列化协议具有良好的可扩展性，支持自动增加新的业务字段，而不影响老的服务，这将大大提供系统的灵活度。<br><strong>安全性 / 访问限制</strong><br>在序列化选型的过程中，安全性的考虑往往发生在跨局域网访问的场景。当通讯发生在公司之间或者跨机房的时候，出于安全的考虑，对于跨局域网的访问往往被限制为基于 HTTP/HTTPS 的 80 和 443 端口。如果使用的序列化协议没有兼容而成熟的 HTTP 传输层框架支持，可能会导致以下三种结果之一：<br>因为访问限制而降低服务可用性；<br>被迫重新实现安全协议而导致实施成本大大提高；<br>开放更多的防火墙端口和协议访问，而牺牲安全性<br><strong>注意点：Android的Parcelable也有安全漏洞</strong></p><p><strong>广义上的序列化和反序列化协议</strong></p><p><strong>XML&amp;SOAP</strong><br><strong>XML</strong> 是一种常用的序列化和反序列化协议，具有跨机器，跨语言等优点，SOAP（Simple ObjectAccess protocol） 是一种被广泛应用的，基于 XML 为序列化和反序列化协议的结构化消息传递协议<br><strong>JSON</strong> 起源于弱类型语言 Javascript， 它的产生来自于一种称之为”Associative array”的概念，其本质是就是采用”Attribute－value”的方式来描述对象。实际上在 Javascript 和 PHP 等弱类型语言中，类的描述方式就是 Associative array。JSON 的如下优点，使得它快速成为最广泛使用的序列化协议之一。这种 Associative array 格式非常符合工程师对对象的理解。它保持了 XML 的人眼可读（Human-readable）的优点。相对于 XML 而言，序列化后的数据更加简洁。 来自于的以下链接的研究表明：XML 所产生序列化之后文件的大小接近 JSON 的两倍它具备 Javascript 的先天性支持，所以被广泛应用于 Web browser 的应用常景中，是 Ajax 的事实标准协议。与 XML 相比，其协议比较简单，解析速度比较快。松散的 Associative array 使得其具有良好的可扩展性和兼容性<br><strong>Protobuf</strong><br>Protobuf 具备了优秀的序列化协议的所需的众多典型特征。<br>标准的 IDL 和 IDL 编译器，这使得其对工程师非常友好。<br>序列化数据非常简洁，紧凑，与 XML 相比，其序列化之后的数据量约为 1/3 到 1/10。<br>解析速度非常快，比对应的 XML 快约 20-100 倍。<br>提供了非常友好的动态库，使用非常简介，反序列化只需要一行代码。</p><p><strong>Android人员如何去选择序列化方案</strong></p><p>Serializable接口<br>Serializable 用来标识当前类可以被 ObjectOutputStream 序列化，以及被 ObjectInputStream 反序列化。</p><p>Parcelable接口<br>Parcelable是Android为我们提供的序列化的接口,Parcelable相对于Serializable的使用相对复杂一些,但Parcelable的效率相对Serializable也高很多,这一直是Google工程师引以为傲的,有时间的可以看一下Parcelable和Serializable的效率对比 Parcelable vs Serializable 号称快10倍的效率</p><p><strong>Serialzable接口</strong></p><p>JAVA提供，依赖于ObjectOutputStream/ObjectInputStream进行操作</p><p><strong>序列化经常会遇到的问题</strong></p><p>1.什么是serialVersionUID，如果不定义这个，会发生什么？</p><p>2.假设你有一个类，他序列化并存储在持久性中，然后修改了该类以添加新字段。如果对已序列化的对象进行反序列化会发生什么情况？</p><p>serialVersionUID的作用<br>serialVersionUID 用来表明类的不同版本间的兼容性。如果你修改了此类, 要修改此值。否则以前用老版本的类序列化的类恢复时会报错: InvalidClassException</p><p>为了在反序列化时，确保类版本的兼容性，最好在每个要序列化的类中加入 private static final long serialVersionUID这个属性，具体数值自己定义。这样，即使某个类在与之对应的对象 已经序列化出去后做了修改，该对象依然可以被正确反序列化。否则，如果不显式定义该属性，这个属性值将由JVM根据类的相关信息计算，而修改后的类的计算 结果与修改前的类的计算结果往往不同，从而造成对象的反序列化因为类版本不兼容而失败。不显式定义这个属性值的另一个坏处是，不利于程序在不同的JVM之间的移植。因为不同的编译器实现该属性值的计算策略可能不同，从而造成虽然类没有改变，但是因为JVM不同，出现因类版本不兼容而无法正确反序列化的现象出现</p><p>因此 JVM 规范强烈 建议我们手动声明一个版本号，这个数字可以是随机的，只要固定不变就可以。同时最好是 private 和 final 的，尽量保证不变。</p><p>3.序列化时，你希望某些成员不要序列化？你如何实现它？</p><p>有时候也会变着形式去问，比如问什么是瞬态trasient 变量？瞬态变量和静态变量会不会得到序列化等，所以，如果你不希望字段是对象状态的一部分，然后声明他静态或者瞬态，根据你的需要，他不会被包含在序列化过程之内</p><p>4.为什么序列化一定需要一个无参构造？</p><p>在序列化的过程中，他将构造函数的信息数据存储在ObjectStreamClass的类中，反序列化是提取到当前数据，拿到cons中的构造属性进行反射调用无参构造</p><p><strong>Parcelable</strong></p><p>Parcelable是因为，在android体系当中，为了应用层面使用便捷，在数据的传输过程中，能够直接应用JAVABean进行数据处理，但是传统的serializable依赖于IO，对于android特定场景跨进程间通信来说效率太慢，大量的应用IO会导致各种资源损耗，所以android另外开辟一套序列化方案，本质上也还是对于JAVA类对象的序列化与反序列化，但是其核心目的是为了解决跨进程间通信问题，而不是为了网络数据传输与持久化保存数据，所以他依托于Binder机制，去掉IO，将数据的传输层应用在内存角度。导致其速度比serializable快</p><p><strong>Parcelable与Serializable对比</strong></p><table><thead><tr><th><strong>类型</strong></th><th><strong>Serializable</strong></th><th><strong>Parcelable</strong></th></tr></thead><tbody><tr><td>操作方案</td><td>通过IO操作，速度慢</td><td>直接在内存操作，效率高</td></tr><tr><td>数据大小</td><td>大小不受限制</td><td>因为Binder，一般不超过1M</td></tr><tr><td>其他</td><td>大量反射，内存碎片多</td></tr></tbody></table><p><strong>面试相关</strong></p><p>1.反序列化后的对象，需要调用构造函数重新构造吗？</p><p>反序列化时，类的构造函数不会被执行</p><p>2.序列前的对象与序列化后的对象是什么关系？==？equal?浅复制？深复制？</p><p>深复制</p><p>3.SerialVersionID的作用是什么？</p><p>4.Android中Intent/Bundle的通信原理及大小限制</p><p>Bundle内部是由ArrayMap实现的，ArrayMap的内部实现是两个数组，一个int数组是存储对象数据对应下标，一个对象数组保存key和value，内部使用二分法对key进行排序，所以在添加、删除、查找数据的时候，都会使用二分法查找，只适合于小数据量操作，如果在数据量比较大的情况下，那么它的性能将退化。而HashMap内部则是数组+链表结构，所以在数据量较少的时候，HashMap的Entry Array比ArrayMap占用更多的内存。因为使用Bundle的场景大多数为小数据量，我没见过在两个Activity之间传递10个以上数据的场景，所以相比之下，在这种情况下使用ArrayMap保存数据，在操作速度和内存占用上都具有优势，因此使用Bundle来传递数据，可以保证更快的速度和更少的内存占用。另外一个原因，则是在Android中如果使用Intent来携带数据的话，需要数据是基本类型或者是可序列化类型，HashMap使用Serializable进行序列化，而Bundle则是使用Parcelable进行序列化。而在Android平台中，更推荐使用Parcelable实现序列化，虽然写法复杂，但是开销更小，所以为了更加快速的进行数据的序列化和反序列化，系统封装了Bundle类，方便我们进行数据的传输。</p><p>Intent 中的 Bundle 是使用 Binder 机制进行数据传送的。能使用的 Binder 的缓冲区是有大小限制的（有些手机是 2 M），而一个进程默认有 16 个 Binder 线程，所以一个线程能占用的缓冲区就更小了（ 有人以前做过测试，大约一个线程可以占用 128 KB）。所以当你看到 The Binder transaction failed because it was too large 这类 TransactionTooLargeException 异常时，你应该知道怎么解决了</p><p>5.为何Intent不能直接在组件间传递对象，而要通过序列化</p><p>Intent在启动其他组件时，会离开当前应用程序进程，进入ActivityManagerService进程（intent.prepareToLeaveProcess()），这也就意味着，Intent所携带的数据要能够在不同进程间传输。首先我们知道，Android是基于Linux系统，不同进程之间的java对象是无法传输，所以我们此处要对对象进行序列化，从而实现对象在 应用程序进程 和 ActivityManagerService进程 之间传输。而Parcel或者Serializable都可以将对象序列化，其中，Serializable使用方便，但性能不如Parcel容器，后者也是Android系统专门推出的用于进程间通信等的接口</p><p>6.序列化与持久化的关系和区别是什么？</p><p>序列化可以将一个复杂的对象转化为一维的数据，而这为持久化提供了很大的方便，因为文件就是一维的，将一维的东西写入文件自然比较方便。</p><p>不过持久化是个很宽泛的概念，可以是写入文件，也可以是存入数据库，写入注册表等多种方式。其本意是延长对象或数据的生命周期，让其可以超越程序的生命周期，程序关闭了，甚至服务器关机了，下次运行程序时又可以让对象或数据恢复到原来的状态。</p><p>而序列化也不一定是用来持久化的，可以是用来传递使用，如从计算机A传递到计算机B；也可以用来进行深拷贝；总之序列化主要解决从复杂的数据结构转化为一维结构，或者从一维结构从新构建复杂的数据结构</p><p><strong>总结</strong></p><p><strong>什么是序列化?</strong><br>本质上就是一套固定数据格式的方案<br>Parcelable与serializable本质区别<br><strong>应用角度：</strong><br>Parcelable目的是为了支持跨进程间数据通信<br>Serializable目的是提供对于JAVA对象的序列化支持，他考虑的场景覆盖全面，IO</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;序列化定义以及相关概念&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于在系统底层，数据的传输形式是简单的字节序列形式传递，即在底层，系统不认识对象，只认识字节序列，而为了达到进程通讯的目的，需要先将数据序列化，而序列化就是将对象转化字节序列的过程。相反地，当字节序列被
      
    
    </summary>
    
    
      <category term="IO" scheme="http://www.yppcat.top/tags/IO/"/>
    
  </entry>
  
  <entry>
    <title>BIO与NIO</title>
    <link href="http://www.yppcat.top/2022/12/05/BIO%E4%B8%8ENIO/"/>
    <id>http://www.yppcat.top/2022/12/05/BIO与NIO/</id>
    <published>2022-12-05T08:33:28.000Z</published>
    <updated>2022-12-05T08:53:54.845Z</updated>
    
    <content type="html"><![CDATA[<p><strong>android 人员对于IO的诉求</strong></p><p>IO对于系统的影响<br>性能层面基础的单位影响<br><strong>使用率</strong>：是指磁盘处理io的时间百分比。过高的使用率(比如超过80%)，通常意味着磁盘io存在性能瓶颈。<br><strong>饱和度</strong>：是指磁盘处理io的繁忙程度。过高的饱和度，意味着磁盘存在着严重的性能瓶颈。当饱和度为100%时，磁盘无法接受新的io请求。<br><strong>IOPS</strong>：是指每秒的io请求数，适用于大量小文件的情景<br><strong>吞吐量</strong>：是指每秒的io请求大小，适用与大文件的情景响应时间：是指io请求从发出到收到响应的时间间隔<br>IO模型对于性能的影响<br><strong>阻塞IO、非阻塞IO、复用IO、信号驱动IO、异步IO</strong></p><p>android对于IO需要注意的场景<br>1.设备（手机）作为S端<br>2.IO复用可能导致的空指针<br>3.设备数据的传递<br>4.dex加壳与脱壳<br>IO的优化是在解决CPU的瓶颈问题，但是通常在C端喝少会出现，所以在学习IO的角度上来说，我们不会吧重点放在CPU瓶颈的解决，而是会探寻IO本质原理及序列化的应用与Dex文件的加壳脱壳</p><p><strong>IO的基本常识-内核空间</strong></p><p>在对于IO学习之前， 我们首先需要了解一定的常识，比如内核、JVM、堆区、这些概念是必备的</p><p>内核=一套软件，操作系统用于支撑基础使用的功能程序</p><p>APP=上层应用–》很多基础功能是需要调用内核去进行完成</p><img src="/2022/12/05/BIO与NIO/image-20221205163514704.png" title="[BIO与NIO]"><p><strong>数据读写的方案</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205163537391.png" title="[BIO与NIO]"><p><strong>内核（linux）的IO栈</strong></p><p><strong>我们可以吧Linux存储系统的io栈，由上到下分为三个层次，分别是文件系统层、通用块层和设备层。</strong><br><strong>文件系统层</strong>，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据。<br><strong>通用块层</strong>，包括块设备io队列和io调度器。它会对文件系统的io请求进行排队，再通过重新排序和请求合并，然后才发送给下一级的设备层。<br><strong>设备层</strong>，包括存储设备和相应的驱动程序，负责最终物理设备的io操作。<br>存储系统的io，通常是整个系统中最慢的一环。所以，Linux通过多种缓存机制来优化io效率。<br>为了优化存储系统访问文件的性能，会使用页缓存、索引节点缓存、目录项缓存等多种缓存机制，以及减少对下层块设备的直接调用。<br>为了优化块设备的访问效率，会使用缓冲区，来缓存块设备的数据。</p><p><strong>内核空间对于IO的操作方案</strong></p><p>页：4K数据为一页， 一页数据是IO操作的基本单位</p><p>空间局部性原理：在常规操作下， 如果数据量较大的情况下可能会出现预占位4~16K的情况</p><p><strong>JAVA 对于Basic IO 的支撑</strong></p><p>Basic IO : API提供的基础功能分析及相关应用场景与特点</p><img src="/2022/12/05/BIO与NIO/image-20221205163812378.png" title="[BIO与NIO]"><p><strong>MappedByteBuffer缓冲区</strong></p><p>java io操作中通常采用BufferedReader，BufferedInputStream等带缓冲的IO类处理大文件，不过java nio中引入了一种基于MappedByteBuffer操作大文件的方式，其读写性能极高</p><p>FileChannel提供了map方法<strong>把文件映射到虚拟内存</strong>，通常情况可以映射整个文件，如果文件比较大，可以进行分段映射。</p><p>MappedByteBuffer使用虚拟内存，因此分配(map)的内存大小不受JVM的-Xmx参数限制，但是也是有大小限制的。<br>如果当文件超出1.5G限制时，可以通过position参数重新map文件后面的内容。<br>MappedByteBuffer在处理大文件时的确性能很高，但也存在一些问题，如内存占用、文件关闭不确定，被其打开的文件只有在垃圾回收的才会被关闭，而且这个时间点是不确定的。<br>javadoc中也提到：A mapped byte buffer and the file mapping that it represents remain valid until the buffer itself is garbage-collected.*</p><p><strong>性能分析</strong></p><p>从代码层面上看，从硬盘上将文件读入内存，都要经过文件系统进行数据拷贝，并且数据拷贝操作是由文件系统和硬件驱动实现的，理论上来说，拷贝数据的效率是一样的。<br>但是通过内存映射的方法访问硬盘上的文件，效率要比read和write系统调用高，这是为什么？</p><p>read()是系统调用，首先将文件从硬盘拷贝到内核空间的一个缓冲区，再将这些数据拷贝到用户空间，实际上进行了两次数据拷贝；<br>map()也是系统调用，但没有进行数据拷贝，当缺页中断发生时，直接将文件从硬盘拷贝到用户空间，只进行了一次数据拷贝。<br>所以，采用内存映射的读写效率要比传统的read/write性能高。</p><p><strong>IO模型概念</strong></p><p>IO分两阶段进行：<br>1.数据准备阶段<br>2.内核空间复制回用户进程缓冲区阶段</p><p>所谓模型就是在这两阶段当中的实现方案</p><p><strong>POSIX</strong></p><p>POSIX(可移植操作系统接口)把同步IO操作定义为导致进程阻塞直到IO完成的操作，反之则是异步IO</p><p><strong>阻塞IO模型</strong>：使用recv的默认参数一直等数据直到拷贝到用户空间，这段时间内进程始终阻塞。A同学用杯子装水，打开水龙头装满水然后离开。这一过程就可以看成是使用了阻塞IO模型，因为如果水龙头没有水，他也要等到有水并装满杯子才能离开去做别的事情。很显然，这种IO模型是同步的。</p><p><strong>非阻塞IO模型</strong>：改变flags，让recv不管有没有获取到数据都返回，如果没有数据那么一段时间后再调用recv看看，如此循环。B同学也用杯子装水，打开水龙头后发现没有水，它离开了，过一会他又拿着杯子来看看……在中间离开的这些时间里，B同学离开了装水现场(回到用户进程空间)，可以做他自己的事情。这就是非阻塞IO模型。但是它只有是检查无数据的时候是非阻塞的，在数据到达的时候依然要等待复制数据到用户空间(等着水将水杯装满)，因此它还是同步IO。</p><p><strong>传统阻塞IO</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205164232129.png" title="[BIO与NIO]"><p><strong>非阻塞IO</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205164249479.png" title="[BIO与NIO]"><p><strong>IO复用模型</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205164310776.png" title="[BIO与NIO]"><p>这里在调用recv前先调用select或者poll，这2个系统调用都可以在内核准备好数据(网络数据到达内核)时告知用户进程，这个时候再调用recv一定是有数据的。因此这一过程中它是阻塞于select或poll，而没有阻塞于recv，有人将非阻塞IO定义成在读写操作时没有阻塞于系统调用的IO操作(不包括数据从内核复制到用户空间时的阻塞，因为这相对于网络IO来说确实很短暂)，如果按这样理解，这种IO模型也能称之为非阻塞IO模型，但是按POSIX来看，它也是同步IO，那么也和楼上一样称之为同步非阻塞IO吧。</p><p>这种IO模型比较特别，分个段。因为它能同时监听多个文件描述符(fd)。这个时候C同学来装水，发现有一排水龙头，舍管阿姨告诉他这些水龙头都还没有水，等有水了告诉他。于是等啊等(select调用中)，过了一会阿姨告诉他有水了，但不知道是哪个水龙头有水，自己看吧。于是C同学一个个打开，往杯子里装水(recv)。这里再顺便说说鼎鼎大名的epoll(高性能的代名词啊)，epoll也属于IO复用模型，主要区别在于舍管阿姨会告诉C同学哪几个水龙头有水了，不需要一个个打开看(当然还有其它区别)。</p><p><strong>信号驱动IO模型</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205164355709.png" title="[BIO与NIO]"><p>通过调用sigaction注册信号函数，等内核数据准备好的时候系统中断当前程序，执行信号函数(在这里面调用recv)。D同学让舍管阿姨等有水的时候通知他(注册信号函数)，没多久D同学得知有水了，跑去装水。是不是很像异步IO？很遗憾，它还是同步IO(省不了装水的时间啊)。</p><p><strong>异步IO模型</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205164437205.png" title="[BIO与NIO]"><p>调用aio_read，让内核等数据准备好，并且复制到用户进程空间后执行事先指定好的函数。E同学让舍管阿姨将杯子装满水后通知他。整个过程E同学都可以做别的事情(没有recv)，这才是真正的异步IO。</p><p><strong>五种IO模型不同</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205164505642.png" title="[BIO与NIO]"><p><strong>IO的五个模型故事解释</strong></p><img src="/2022/12/05/BIO与NIO/image-20221205164527837.png" title="[BIO与NIO]"><p><strong>OKIO对于JAVAIO的优化</strong></p><p>官方的解释是这样的：Okio是一个库，是对java.io和java.nio的补充，通过这个库，我们可以更简单的使用和存储我们的数据。</p><p>Okio提供了两种新的类型，这两种类型有很多新的功能，并且使用比较简单。这两中类型分别是：ByteString和Buffer。</p><p>ByteString是不可变的字节序列（请参考String，String是不可变的字符串）。String是基本的字符数据，ByteString相当于是String的兄弟，ByteString让处理二进制数据变得简单了。这个类是符合人们的编程习惯的，它知道怎么使用比如hax，base64,UTF-8等编码格式将它自己编码或解码。</p><p>Buffer是一个可变的字符序列。你不需要提前设置它的大小，它在写入数据的时候会将数据放在最后，而在读取的时候会在最前面开始读取（这很类似与队列），你也不需要关心它的位置，限制，容量等等。</p><p><strong>OKIO 采取的方案</strong></p><p>OKIO在读取数据时，先从Buffer对象中获取了一个Segment，然后向Segment中读取数据，每个Segment最多可以存入8K数据。这里需要提一下Buffer中数据的数据结构，Buffer中的数据是存在于一个双向链表中，链表中的每个节点都是一个Segment</p><img src="/2022/12/05/BIO与NIO/image-20221205164615902.png" title="[BIO与NIO]"><img src="/2022/12/05/BIO与NIO/image-20221205164632285.png" title="[BIO与NIO]"><p><strong>OKIO 解决了什么</strong></p><p>不管是读入还是写出，缓冲区的存在必然涉及copy的过程，而如果涉及双流操作，比如从一个输入流读入，再写入到一个输出流，那么这种情况下，在缓冲存在的情况下，数据走向是：<br>-&gt; 从输入流读出到缓冲区<br>-&gt; 从输入流缓冲区copy到 b[]<br>-&gt; 将 b[] copy 到输出流缓冲区<br>-&gt; 输出流缓冲区读出数据到输出流</p><p>OK是将两个缓冲合并成一份</p><p><strong>Okio核心竞争力</strong>为，增强了流于流之间的互动，使得当数据从一个缓冲区移动到另一个缓冲区时，可以不经过copy能达到：</p><p>以Segment作为存储结构，真实数据以类型为byte[]的成员变量data存在，并用其它变量标记数据状态，在需要时，如果可以，移动Segment引用，而非copy data数据<br>Segment在Segment线程池中以单链表存在以便复用，在Buffer中以双向链表存在存储数据，head指向头部，是最老的数据<br>Segment能通过slipt()进行分割，可实现数据共享，能通过compact()进行合并。由Buffer来进行数据调度，基本遵守 “大块数据移动引用，小块数据进行copy” 的思想<br>Source 对应输入流，Sink 对应输出流<br>TimeOut 以达到在期望时间内完成IO操作的目的，同步超时在每次IO操作中检查耗时，异步超时开启另一线程间隔时间检查耗时</p><p>OK核心是解决双流操作的问题</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;android 人员对于IO的诉求&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;IO对于系统的影响&lt;br&gt;性能层面基础的单位影响&lt;br&gt;&lt;strong&gt;使用率&lt;/strong&gt;：是指磁盘处理io的时间百分比。过高的使用率(比如超过80%)，通常意味着磁盘io存在性能瓶颈
      
    
    </summary>
    
    
      <category term="IO" scheme="http://www.yppcat.top/tags/IO/"/>
    
  </entry>
  
  <entry>
    <title>AQS</title>
    <link href="http://www.yppcat.top/2022/12/05/AQS/"/>
    <id>http://www.yppcat.top/2022/12/05/AQS/</id>
    <published>2022-12-05T00:05:16.000Z</published>
    <updated>2022-12-05T00:16:55.258Z</updated>
    
    <content type="html"><![CDATA[<p><strong>什么是AQS？</strong></p><p>AQS，全程AbstractQueuedSynchronizer，位于java.util.concurrent.locks包下。</p><p>是JDK1.5提供的一套用于实现阻塞锁和一系列依赖FIFO等待队列的同步器(First Input First Output先进先出)的框架实现。是除了java自带的synchronized 关键字之外的锁机制。 可以将AQS作为一个队列来理解。</p><p>我们常用的ReentrantLock、Semaphore、CountDownLatch、CyclicBarrier等并发类均是基于AQS来实现的。具体用法是通过继承AQS，并实现其模板方法，来达到同步状态的管理。</p><p>AQS的功能在使用中可以分为两种:独占锁和共享锁<br>独占锁：每次只能有一个线程持有锁。eg: ReentrantLock就是独占锁<br>共享锁：允许多个线程同时获得锁，并发访问共享资源。eg: ReentrantReadWriteLock中的读</p><p><strong>AQS核心思想</strong></p><p>AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。</p><img src="/2022/12/05/AQS/image-20221205080624705.png" title="[AQS]"><p><strong>AQS使用方式</strong></p><p>AQS设计是基于模板方法模式的，一般的使用方式是：<br>使用者继承AbstractQueuedSynchronizer并重写指定的方法。（这些重写方法很简单，无非是对于共享资源state的获取和释放）</p><p>将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。</p><p>AQS定义的这些可重写的方法：<br>protected boolean tryAcquire(int arg): 独占式获取同步状态，试着获取，成功返回true，反之为false<br>protected boolean tryRelease(int arg) ：独占式释放同步状态，等待中的其他线程此时将有机会获取到同步状态；<br>protected int tryAcquireShared(int arg) ：共享式获取同步状态，返回值大于等于0，代表获取成功；反之获取失败；<br>protected boolean tryReleaseShared(int arg) ：共享式释放同步状态，成功为true，失败为false<br>protected boolean isHeldExclusively()： 是否在独占模式下被线程占用。</p><p><strong>AQS的模板方法</strong></p><p><strong>独占锁：</strong><br>void acquire(int arg);// 独占式获取同步状态，如果获取失败则插入同步队列进行等待；<br>void acquireInterruptibly(int arg);// 与acquire方法相同，但在同步队列中进行等待的时候可以检测中断；<br>boolean tryAcquireNanos(int arg, long nanosTimeout);// 在acquireInterruptibly基础上增加了超时等待功能，在超时时间内没有获得同步状态返回false;<br>boolean release(int arg);// 释放同步状态，该方法会唤醒在同步队列中的下一个节点</p><p><strong>共享锁：</strong><br>void acquireShared(int arg);// 共享式获取同步状态，与独占式的区别在于同一时刻有多个线程获取同步状态；<br>void acquireSharedInterruptibly(int arg);// 在acquireShared方法基础上增加了能响应中断的功能；<br>boolean tryAcquireSharedNanos(int arg, long nanosTimeout);// 在acquireSharedInterruptibly基础上增加了超时等待的功能；<br>boolean releaseShared(int arg);// 共享式释放同步状态</p><p>自定义，使用总结</p><p>首先，我们需要去继承AbstractQueuedSynchronizer这个类，然后我们根据我们的需求去重写相应的方法，比如要实现一个独占锁，那就去重写tryAcquire，tryRelease方法，要实现共享锁，就去重写tryAcquireShared，tryReleaseShared；</p><p>然后，在我们的组件中调用AQS中的模板方法就可以了，而这些模板方法是会调用到我们之前重写的那些方法的。也就是说，我们只需要很小的工作量就可以实现自己的同步组件，重写的那些方法，仅仅是一些简单的对于共享资源state的获取和释放操作，至于像是获取资源失败，线程需要阻塞之类的操作，自然是AQS帮我们完成了</p><p><strong>AQS源码分析</strong></p><p>AQS的基本实现：<br>    AQS维护一个共享资源state，通过内置的FIFO来完成获取资源线程的排队工作。（这个内置的同步队列称为”CLH”队列）。该队列由一个一个的Node结点组成，每个Node结点维护一个prev引用和next引用，分别指向自己的前驱和后继结点。AQS维护两个指针，分别指向队列头部head和尾部tail。<br>    当线程获取资源失败（比如tryAcquire时试图设置state状态失败），会被构造成一个结点加入CLH队列中，同时当前线程会被阻塞在队列中（通过LockSupport.park实现，其实是等待态）。当持有同步状态的线程释放同步状态时，会唤醒后继结点，然后此结点线程继续加入到对同步状态的争夺中。</p><img src="/2022/12/05/AQS/image-20221205080912795.png" title="[AQS]"><p><strong>ReentrantLock与AQS</strong></p><img src="/2022/12/05/AQS/image-20221205080936878.png" title="[AQS]"><p><strong>ReentrantLock加锁流程</strong>    </p><img src="/2022/12/05/AQS/image-20221205080956123.png" title="[AQS]"><img src="/2022/12/05/AQS/aqs加锁流程图.png" title="[AQS]"><p><strong>条件变量实现原理</strong></p><p>每个条件变量其实就对应着一个等待队列，其实现类是 ConditionObject</p><p>await 流程<br>开始 Thread-0 持有锁，调用 await，进入 ConditionObject 的 addConditionWaiter 流程<br>创建新的 Node 状态为 -2（Node.CONDITION），关联 Thread-0，加入等待队列尾部</p><img src="/2022/12/05/AQS/image-20221205081119159.png" title="[AQS]"><p><strong>同步方案对比</strong></p><p>wait/notify：依托于synchronized，基于VM底层对于阻塞的实现，使用waitSet作为等待机制，set结构的问题，要么是随机一个（set的提取算法），要么是全部提出来唤醒</p><p>await/signal：依赖于ReentrantLock条件变量，已经用条件变量与AQS体系作为唤醒机制，本质上底层是park/unpark实现阻塞</p><p>park/unpark:以thread为操作对象,操作更精准，可以准确地唤醒某一个线程（notify随机唤醒一个线程，notifyAll唤醒所有等待的线程），增加了灵活性。</p><p>其实park/unpark的设计原理核心是“许可”：park是等待一个许可，unpark是为某线程提供一个许可</p><p>但是这个“许可”是不能叠加的，“许可”是一次性的。<br>比如线程B连续调用了三次unpark函数，当线程A调用park函数就使用掉这个“许可”，如果线程A再次调用park，则进入等待状态。</p><p><strong>ReentrantReadWriteLock读写锁</strong></p><p><strong>读写锁指一个资源能够被多个读线程访问，或者被一个写线程访问，但是不能同时存在读写线程</strong><br>ReentrantReadWriteLock中有两个静态内部类：ReadLock读锁和WriteLock写锁，这两个锁实现了Lock接口ReentrantReadWriteLock支持可重入，同步功能依赖自定义同步器（AbstractQueuedSynchronizer）实现，读写状态就是其同步器的同步状态</p><p><strong>写锁的获取和释放</strong>：<br>写锁WriteLock是支持重进入的排他锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取读锁时，读锁已经被获取或者该线程不是已获取写锁的线程，则当前线程进入等待状态。读写锁确保写锁的操作对读锁可见。写锁释放每次减少写状态，当前写状态为0时表示写锁已背释放。</p><p><strong>读锁的获取与释放：</strong><br>读锁ReadLock是支持重进入的共享锁（共享锁为shared节点，对于shared节点会进行一连串的唤醒，知道遇到一个读节点），它能够被多个线程同时获取，在没有其他写线程访问（写状态为0）时，读锁总是能够被成功地获取，而所做的也只是增加读状态（线程安全）。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已经被获取，则进入等待状态。</p><p><strong>CyclicBarrier和CountDownLatch</strong></p><p>CountDownLatch：一个或者多个线程，等待其他多个线程完成某件事情之后才能执行；</p><p>CyclicBarrier：多个线程互相等待，直到到达同一个同步点，再继续一起执行。而且可以重用</p><p>CountDownLatch是计数器，线程完成一个记录一个，只不过计数不是递增而是递减，而CyclicBarrier更像是一个阀门，需要所有线程都到达，阀门才能打开，然后继续执行。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;什么是AQS？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;AQS，全程AbstractQueuedSynchronizer，位于java.util.concurrent.locks包下。&lt;/p&gt;
&lt;p&gt;是JDK1.5提供的一套用于实现阻塞锁和一系列依赖FIFO等待队列
      
    
    </summary>
    
    
      <category term="JUC" scheme="http://www.yppcat.top/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>线程池</title>
    <link href="http://www.yppcat.top/2022/12/03/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    <id>http://www.yppcat.top/2022/12/03/线程池/</id>
    <published>2022-12-03T11:49:42.000Z</published>
    <updated>2022-12-03T12:03:06.462Z</updated>
    
    <content type="html"><![CDATA[<p><strong>异步模式之工作线程</strong></p><p>让有限的工作线程轮流异步处理无限多的任务，也可以将其归类为分工模式，他的典型实现就是线程池，也体现了经典设计模式中的享元模式</p><p>例如,海底捞的服务员（线程），轮流处理每位顾客的点餐（任务），如果每位顾客都配一个专属服务员，则成本太过高昂</p><p>注意：不同任务类型应该使用不同的线程池，这样能够避免饥饿现象，且效率上得到合理分配</p><p>线程饥饿现象：<br>    本质上是在出现多任务混合在同一个池中，如果出现相互影响的状况出现类似死锁的问题</p><p><strong>享元设计模式</strong></p><p>本质：运用内存共享的原理，去有效支撑大量的细颗粒度的对象</p><p>享元工厂：一个享元工厂，用来创建并管理对象，他主要是用来确保合理地共享对象，当用户请求一个对象是，由工厂提供一个已创建的对象示例或者创建一个</p><p>享元对象：一个重复的对象</p><p>使用场景：如果一个程序对于某个对象进行大量应用，且使用生命周期短，可以考虑采取享元模式进行复用</p><p><strong>线程数量与核心数</strong></p><p>处理器核数：<br>    线程核心数是一种执行资源，资源数量就是核的个数，应用程序的线程数就是服务请求数，而操作系统的作用如何调配有限的资源来服务更多的请求，这就是进程调度的概念。<br>一般情况下，服务其你去线程会“相对公平”的分配到核上运行，并且在时间片上轮流使用，这就是所谓的并发执行。</p><p>比如系统有4个核，如果<br>3个线程，分配到3个核上<br>8个线程，每个核分配两个线程执行<br>10个线程，有些核跑3个有些跑2个</p><p>所以，并非线程数量越大，速度越快，线程数量太过于庞大会导致各种内存问题，因为一个线程的开辟还会涉及到线程上下文的应用</p><p><strong>创建多少线程合适？</strong></p><img src="/2022/12/03/线程池/image-20221203195303524.png" title="[线程池]"><p><strong>CPU密集型运算：</strong><br>    通常采用CPU核数 + 1 能够实现最优的CPU利用率，+1是保证当线程由于页缺失故障（操作系统）或其他原因导致暂停时，额外的这个线程就能顶上去，保证CPU始终周期不被浪费</p><p><strong>I/O密集型运算：</strong><br>    CPU不总是处于繁忙状态，例如，当你执行业务计算时，这时候会使用CPU资源，但当你执行IO操作、或者远程的RPC调用时，包括进行数据库操作等，这个时候CPU会闲下来，你可以利用多线程提高他的利用率</p><p><strong>经验公式如下：</strong><br><strong>线程数 = 核数 <em> 期望CPU利用率 </em> 总时间（CPU计算时间+等待时间） / CPU计算时间</strong></p><p>例如：4核CPU，计算时间是50%，其他等待时间是50%，期望CPU被100%利用，套用公式<br>    4 <em> 100% </em> 100% / 50% = 8</p><p><strong>自定义线程池</strong></p><p>由主线程往一个队列中去添加任务，由线程池控制线程去进行消费</p><img src="/2022/12/03/线程池/image-20221203195417333.png" title="[线程池]"><p><strong>JDK中提供的线程池</strong></p><img src="/2022/12/03/线程池/image-20221203195509261.png" title="[线程池]"><p><strong>ThreadPoolExecutor</strong></p><p><strong>状态模型：</strong></p><img src="/2022/12/03/线程池/image-20221203195533485.png" title="[线程池]"><p><strong>构造方法</strong></p><img src="/2022/12/03/线程池/image-20221203195601076.png" title="[线程池]"><p><strong>工作模式</strong></p><img src="/2022/12/03/线程池/image-20221203195622021.png" title="[线程池]"><p><strong>JDK中的拒绝策略</strong></p><p>ThreadPoolExecutor自己已经提供了四个拒绝策略，分别是</p><p>CallerRunsPolicy：在任务被拒绝添加后，会调用当前线程池的所在的线程去执行被拒绝的任务。这个策略的缺点就是可能会阻塞主线程。</p><p>AbortPolicy：默认的拒绝策略就是AbortPolicy。直接抛出异常。抛出个RejectedExecutionException异常，也不执行这个任务了</p><p>DiscardPolicy：这个东西什么都没干。</p><p>DiscardOldestPolicy：当任务呗拒绝添加时，会抛弃任务队列中最旧的任务也就是最先加入队列的，再把这个新任务添加进去。</p><p><strong>变量压缩合并的好处</strong></p><img src="/2022/12/03/线程池/image-20221203195711488.png" title="[线程池]"><p><strong>合并算法</strong></p><p>目的：将另个整数值打包到一个整数值下</p><p>步骤：<br>    1.拆分短位与长位数值      短位=常量（状态）         长位 = 动态值（长度）<br>    2.打包算法   :<br>        长位 &amp; ~ mask | 短位 &amp; mask<br>    mask为分界位，如 一个整数值 短位占用3位，则长位占用29位，mask作用是用来对于短位数值进行换算，所有，如果短位需要占用三位则需要用111&lt;&lt;29位来占据前三位作为等值</p><p><strong>ThreadPoolExecutor与当前自定义的区别</strong></p><p>1.救急线程的应用<br>    提升性能</p><p>2.状态设置<br>    对于线程池的管理</p><p>3.原子合并<br>    利用位运算，进行CAS的优化</p><p>4.工厂模式的应用</p><p><strong>Timer缺点</strong></p><p>Timer的优点在于简单易用，但是由于所有任务都是同一线程来调度执行，所有任务是串行，如果前面任务有延迟，会影响后面任务执行</p><p>解决办法：<br>    ScheduledExecutorService<br>    线程池的调度</p><p><strong>fork/join线程池</strong></p><p>fork/join是JDK 1.7后加入的心得线程池实现，他主要体现是分治思想，适用于能够进行任务拆分的CPU密集型运算</p><p>他是为了处理大数据诞生的</p><p>所谓任务拆分，是将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序、斐波拉切数列，都可以进行分治完成</p><p>Fork/Join在分治的基础上加入了多线程，可以把每个任务的分解和合并交给不同的线程来完成，进一步提升运算效率</p><p>Fork/Join 默认会创建于CPU核心数大小相同的线程池</p><p>最常见业务，对于文件夹的操作</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;异步模式之工作线程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;让有限的工作线程轮流异步处理无限多的任务，也可以将其归类为分工模式，他的典型实现就是线程池，也体现了经典设计模式中的享元模式&lt;/p&gt;
&lt;p&gt;例如,海底捞的服务员（线程），轮流处理每位顾客的点餐（任务），如果
      
    
    </summary>
    
    
      <category term="JUC" scheme="http://www.yppcat.top/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>CAS与原子变量</title>
    <link href="http://www.yppcat.top/2022/11/27/CAS%E4%B8%8E%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F/"/>
    <id>http://www.yppcat.top/2022/11/27/CAS与原子变量/</id>
    <published>2022-11-27T13:08:34.000Z</published>
    <updated>2022-11-28T01:54:19.332Z</updated>
    
    <content type="html"><![CDATA[<p><strong>为什么无锁状态下的运行效率会高？</strong></p><p><strong>单纯的CAS理论：</strong></p><p>单纯的CAS理论只是为了完成一次比较确认值的同步<br>与代码块的同步并没有关系</p><p><strong>CAS理论应用下的锁实现原理：</strong><br>利用volatile变量与CAS理论保证在一定时间段内变量结果的一致性<br>同步对于线程进行阻塞</p><p><strong>CAS无锁状态下与synchronize有锁状态下的本质区别</strong><br>无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而synchronized会让线程在没有获得锁的时候，发生上下文切换，进入阻塞<br>比喻：高速上飙车，当前自己开200码，正常的高速运行，但是一旦发生上下文切换，需要减速停车，换路，在加速，代价相对高昂<br>无锁状态下，因为线程需要保持运行，则需要额外CPU的支持，CPU在这里就是高速公路，没路我们走不下去，一开始没有加锁，不会有阻塞，但是没有时间片，会导致上下文切换，所以CAS需要有多核CPU对于其进行支撑，单核体系下效率不一定</p><p><strong>CAS效率分析</strong></p><p>结合CAS与volatile实现无锁并发情况的适用场景：<br>    多核CPU场景下，且线程数少<br><strong>CAS基于乐观锁思想</strong>，最乐观结果，不怕别的线程来修改共享变量，改了也没事，我在重试<br><strong>synchronize基于悲观锁思想</strong>：最悲观结果，得放着其他线程来修改共享变量，我上锁，你们都别改，我改了解开你们才有机会</p><p>CAS体现的是无锁并发，无阻塞并发<br>    因为没有synchronized，线程不会陷入阻塞，这是效率提升的因素之一<br>    如果竞争几率，重试必然发生频繁，效率会下降</p><p>最好结果为线程数不超过CPU核心数</p><p><strong>线程的上下文切换</strong></p><p>本质：CPU切换前把当前任务的状态保存下来，以便下次切换回这个任务时可以再次加载这个任务的状态，然后加载下一任务的状态并执行。任务的状态保存及再加载, 这段过程就叫做上下文切换。</p><p>每个线程都有一个程序计数器（记录要执行的下一条指令），一组寄存器（保存当前线程的工作变量），堆栈（记录执行历史，其中每一帧保存了一个已经调用但未返回的过程）。</p><p>寄存器 是 CPU 内部的数量较少但是速度很快的内存（与之对应的是 CPU 外部相对较慢的 RAM 主内存）。寄存器通过对常用值（通常是运算的中间值）的快速访问来提高计算机程序运行的速度。</p><p>程序计数器是一个专用的寄存器，用于表明指令序列中 CPU 正在执行的位置，存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置。</p><p>上下文切换会导致额外的开销，常常表现为高并发执行时速度会慢串行，因此减少上下文切换次数便可以提高多线程程序的运行效率。</p><p>直接消耗：指的是CPU寄存器需要保存和加载, 系统调度器的代码需要执行, TLB实例需要重新加载, CPU 的pipeline需要刷掉<br>间接消耗：指的是多核的cache之间得共享数据, 间接消耗对于程序的影响要看线程工作区操作数据的大小</p><p><strong>Atomic Variables（原子变量）</strong></p><p>本质上是一组工具，位置在atomic包下</p><p>​    处理并发安全问题上：<br>​        1.单个原子处理<br>​        2.块处理</p><p>​    本质上分类两类，<br>​        1.保证基本数据类型的原子性（AtomicInteger…）<br>​        2.保证引用类型的原子性（AtomicReference）</p><p><strong>原子引用与ABA问题</strong></p><p><strong>ABA问题</strong>：<br>    在多线程对于原子变量操作时，会发生将数据变更回去的现象，CAS在判断时会造成概念上的认知错误，但是实际上对业务结果是不变的</p><p>但是实际业务运用过程中可能会需要知道整个运行过程值是否改变</p><p>通过AtomicStampedReference  追溯版本号<br>通过AtomicMarkableReference 得到是否更改结果</p><p><strong>不同场景下的原子变量操作方案</strong></p><p>AtomicReference本质上是对于引用类型的地址<br>但是我们常规使用中，更多的业务是要判定内部数据是否一致<br>原子数组：<br>    保证数组内元素的线程安全<br>字段：<br>    字段更新器   AtomicReferenceFieldUpdater<br>累加业务：<br>    原子累加器</p><p><strong>LongAdder与Atomic比较</strong></p><p>性能提升的原因很简单，就是有竞争时，设置多个累加单元，然后最后结果汇总，他这样的累加操作不同的cell变量，因此减少了Cas重试失败，从而提高性能</p><p><strong>LongAdder原理分析</strong></p><p>性能提升的原因很简单，就是有竞争时，设置多个累加单元，然后最后结果汇总，他这样的累加操作不同的cell变量，因此减少了Cas重试失败，从而提高性能</p><img src="/2022/11/27/CAS与原子变量/image-20221127211502227.png" title="[CAS与原子变量]"><p><strong>LongAdder伪共享原理与缓存行</strong></p><p>什么是伪共享？</p><p>​    CPU高度缓冲器的存储体系下，一个基本的缓存单位叫做缓存行，一个缓存行的大小为64byte,<br>​    数组是一块连续的空间，因为副本数据的原因，数组加载到缓存当中，数据超过64字节会占用多行,若小于64字节则占用一行</p><p><strong>总结</strong></p><p>对于并发处理，从业务角度我们看做为两块：</p><p>​    1.原子变量操作</p><p>​    2.业务代码块的并发</p><p>并发手段现在接触的是两种：</p><p>​    1.加锁并发：synchronize（悲观体现）</p><p>​    2.无锁并发：CAS应用实现（乐观体现）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;为什么无锁状态下的运行效率会高？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;单纯的CAS理论：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;单纯的CAS理论只是为了完成一次比较确认值的同步&lt;br&gt;与代码块的同步并没有关系&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CAS理论应
      
    
    </summary>
    
    
      <category term="JUC" scheme="http://www.yppcat.top/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>锁</title>
    <link href="http://www.yppcat.top/2022/11/24/%E9%94%81/"/>
    <id>http://www.yppcat.top/2022/11/24/锁/</id>
    <published>2022-11-24T00:33:55.000Z</published>
    <updated>2022-11-24T00:44:09.608Z</updated>
    
    <content type="html"><![CDATA[<p><strong>JAVA下的线程安全分析</strong></p><p>在系统处理过程中，最为常见的问题是同一线程对于相同资源进行访问所造成的数据处理异常问题</p><p>下面代码中可能出现的结果是多少？</p><img src="/2022/11/24/锁/image-20221124083439437.png" title="[锁]"><p>出现问题的过程指令分析-线程的上下文切换</p><img src="/2022/11/24/锁/image-20221124083501485.png" title="[锁]"><p><strong>临界区与竞态条件</strong></p><p><strong>临界区：</strong><br>一个程序运行多个线程本身没有问题<br>出现问题最大的地方在于多个线程访问共享资源<br>多个线程读共享资源其实也没有问题<br>在多个线程对共享资源读写操作时发生指令交错，就会出现问题<br>一段代码块内如果存在对共享资源的多线程读写操作，称这段代码为临界区</p><p><strong>竞态条件:</strong><br>多个线程在临界区内执行，由于代码执行序列不同而导致结果无法预测，称之为静态条件</p><img src="/2022/11/24/锁/image-20221124083546506.png" title="[锁]"><p><strong>应用之互斥</strong></p><p>为了避免临界区的竞态条件发生，JAVA提供多种手段进行规避<br>阻塞式的解决方案：synchronized,Lock<br>非阻塞式的解决方案：原子变量</p><p>synchronized对象锁：<br>采用互斥方式让统一时刻之多只有一个线程持有对象锁，其他线程在获取这个对象锁会被阻塞，不用担心线程上下文切换</p><p>synchronized—本质与等价方案</p><img src="/2022/11/24/锁/image-20221124083638396.png" title="[锁]"><p><strong>Mark中的数据对于并发的支持</strong></p><img src="/2022/11/24/锁/image-20221124083721097.png" title="[锁]"><img src="/2022/11/24/锁/image-20221124083734688.png" title="[锁]"><p><strong>Monitor对象与synchronized</strong></p><img src="/2022/11/24/锁/image-20221124083750276.png" title="[锁]"><p><strong>注意事项</strong></p><p>执行同步代码块内容，然后唤醒entryList中其他线程时，此处采取竞争策略，先到不一定先得，所以synchronize锁是非公平</p><p>非公平锁： 在锁可用的时候，一个新到来的线程要占有锁，可以不需要排队，直接获得。</p><p>公平锁： 在锁可用的时候，一个新到来的线程要占有锁，需要排队，等待执行</p><p><strong>有没有比synchronized速度更快的方案？</strong></p><p>利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法。其它原子操作都是利用类似的特性完成的。而整个J.U.C都是建立在CAS之上的，因此对于synchronized阻塞算法，J.U.C在性能上有了很大的提升。</p><p><strong>什么是CAS？</strong></p><p>CAS是英文单词Compare And Swap的缩写，翻译过来就是比较并替换。</p><p>CAS机制当中使用了3个基本操作数：<br>内存地址V<br>旧的预期值A<br>要修改的新值B</p><p>更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。</p><p>CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B。</p><img src="/2022/11/24/锁/image-20221124084005051.png" title="[锁]"><img src="/2022/11/24/锁/image-20221124084041320.png" title="[锁]">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;JAVA下的线程安全分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在系统处理过程中，最为常见的问题是同一线程对于相同资源进行访问所造成的数据处理异常问题&lt;/p&gt;
&lt;p&gt;下面代码中可能出现的结果是多少？&lt;/p&gt;
&lt;img src=&quot;/2022/11/24/锁/imag
      
    
    </summary>
    
    
      <category term="JUC" scheme="http://www.yppcat.top/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>JMM内存模型与线程并发</title>
    <link href="http://www.yppcat.top/2022/11/23/JMM%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91/"/>
    <id>http://www.yppcat.top/2022/11/23/JMM内存模型与线程并发/</id>
    <published>2022-11-23T00:09:15.000Z</published>
    <updated>2022-11-23T00:27:46.051Z</updated>
    
    <content type="html"><![CDATA[<p><strong>多核并发缓存架构解析</strong></p><p><strong>CPU 核心数和线程数的关系</strong></p><p>多核心:也指单芯片多处理器( Chip Multiprocessors,简称 CMP),CMP 是由美国斯坦福大学提出的,其思想是将大规模并行处理器中的 SMP(对称多处理器)集成到同一芯片内,各个处理器并行执行不同的进程。这种依靠多个 CPU 同时并行地运行程序是实现超高速计算的一个重要方向,称为并行处理</p><p>多线程: Simultaneous Multithreading.简称 SMT.让同一个处理器上的多个线程同步执行并共享处理器的执行资源。<br>核心数、线程数:目前主流 CPU 都是多核的。增加核心数目就是为了增加线程数,因为操作系统是通过线程来执行任务的,一般情况下它们是 1:1 对应关系,也就是说四核 CPU 一般拥有四个线程。但 Intel 引入超线程技术后,使核心数与线程数形成 1:2 的关系</p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081135874.png" title="[JMM内存模型与线程并发]"><p><strong>CPU 时间片轮转机制</strong></p><p>时间片轮转调度中唯一有趣的一点是时间片的长度。从一个进程切换到另一个进程是需要定时间的,包括保存和装入寄存器值及内存映像,更新各种表格和队列等。假如进程切( processwitch),有时称为上下文切换( context switch),需要 5ms, 再假设时间片设为 20ms,则在做完 20ms 有用的工作之后,CPU 将花费 5ms 来进行进程切换。CPU 时间的 20%被浪费在了管理开销上了。<br>为了提高 CPU 效率,我们可以将时间片设为 5000ms。这时浪费的时间只有0.1%。但考虑到在一个分时系统中,如果有 10 个交互用户几乎同时按下回车键, 将发生什么情况?假设所有其他进程都用足它们的时间片的话,最后一个不幸的进程不得不等待 5s 才获得运行机会。多数用户无法忍受一条简短命令要 5 才能做出响应。<br>结论可以归结如下:时间片设得太短会导致过多的进程切换,降低了CPU 效率: 而设得太长又可能引起对短的交互请求的响应变差。将时间片设为 100ms 通常是一个比较合理的折衷</p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081047224.png" title="[JMM内存模型与线程并发]"><p><strong>并发与并行</strong></p><p>我们举个例子,如果有条高速公路 A 上面并排有 8 条车道,那么最大的并行车辆就是 8 辆此条高速公路 A 同时并排行走的车辆小于等于 8 辆的时候,车辆就可以并行运行。CPU 也是这个原理,一个 CPU 相当于一个高速公路 A,核心数或者线程数就相当于并排可以通行的车道;而多个CPU  就相当于并排有多条高速公路,而每个高速公路并排有多个车道。<br>当谈论并发的时候一定要加个单位时间,也就是说单位时间内并发量是多少?    离开了单位时间其实是没有意义的。<br>俗话说,一心不能二用,这对计算机也一样,原则上一个 CPU 只能分配给一个进程,以便运行这个进程。我们通常使用的计算机中只有一个 CPU,也就是说只有一颗心,要让它一心多用同时运行多个进程,就必须使用并发技术。实现并发技术相当复杂,最容易理解的是“时间片轮转进程调度算法”。</p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081215966.png" title="[JMM内存模型与线程并发]"><p><strong>CPU物理内核架构</strong></p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081303369.png" title="[JMM内存模型与线程并发]"><p><strong>多核CPU缓存架构</strong></p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081334365.png" title="[JMM内存模型与线程并发]"><p><strong>JMM内存模型</strong></p><p>JAVA多线程内存模型跟CPU内存模型类似，是基于CPU缓存模型来建立的，java线程内存模型是标准化的，屏蔽了底层计算机的不同</p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081409704.png" title="[JMM内存模型与线程并发]"><p><strong>JMM内存模型8大原子操作</strong></p><p><strong>read(读取)：从主内存中读取数据</strong><br><strong>load(载入)：将主内存读取到的数据写入工作内存</strong><br><strong>use(使用)：从工作内存读取数据来计算</strong><br><strong>assign(赋值)：将计算好的值重新赋值到工作内存当中</strong><br><strong>store(存储)：将工作内存数据写入主内存</strong><br><strong>write(写入)：将存入的数据变量值赋值给主内存中的共享变量</strong><br><strong>lock(锁定)：将主内存变量加锁</strong><br><strong>unlock(解锁)：将主内存变量解锁</strong></p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081454988.png" title="[JMM内存模型与线程并发]"><p><strong>缓存一致协议（MESI）：</strong><br>多个CPU从主内存读取同一个数据到各自的高速缓存，当其中某个CPU修改了缓存里的数据，该数据马上同步会主内存，其他的CPU通过总线嗅探机制可以感知到数据的变化从而将自己缓存的数据失效</p><p><strong>缓存加锁：</strong><br>缓存锁的核心机制是遵循与缓存一致性协议，一个处理器的缓存回写到内存会导致其他处理器的缓存失效，IA-32和Inter 64处理器使用MESI实现缓存一致性协议，Arm架构下是AMBA协议</p><p><strong>Volatile可见性底层实现原理</strong></p><p>Volatile缓存可见性实现原理：<br>底层实现主要通过一条汇编指令lock前缀指令，他会锁定这块内存区域的缓存（缓存行锁定）并写回到主内存中<br>Inter架构软件开发者手册中对lock指令的解释：<br>会将当前处理器缓存行的数据立即写回到系统内存<br>这个写回内存操作会引起其他CPU缓存了该地址的数据无效(MESI)<br>提供内存屏障功能，是lock指令不会进行重排</p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081614247.png" title="[JMM内存模型与线程并发]"><p><strong>JAVA底层对应转换汇编语言查看</strong></p><p>-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*JMMTest.prepare</p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123081642431.png" title="[JMM内存模型与线程并发]"><p><strong>dex工具使用</strong></p><p>工具位置：SDK目录下\build-tools\版本\dx.bat<br>使用方式：配置该路径为环境变量<br>作用：将.class编译为dex字节码<br>转换指令：<br>dx –dex –min-sdk-version=28 –verbose –dump-to=JmmTest.dex.txt –dump-method=JMMTest.prepare  –verbose-dump JMMTest.class</p><p>-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*VolatileVisibilltyTest.prepareData</p><p><strong>指令重排序</strong></p><p>在计算机执行指令的顺序在经过程序编译器编译之后形成的指令序列</p><p>一般而言，这个指令序列是会输出确定的结果；以确保每一次的执行都有确定的结果</p><p>但是，一般情况下，CPU和编译器为了提升程序执行的效率，会按照一定的规则允许进行指令优化</p><p>在某些情况下，这种优化会带来一些执行的逻辑问题，主要的原因是代码逻辑之间是存在一定的先后顺序</p><p>在并发执行情况下，会发生二义性，即按照不同的执行逻辑，会得到不同的结果信息。</p><p><strong>规则:  改变指令的先后顺序会导致最终的结果不一致，则不会发生指令重排,反之 如果不会发生结果不一致则会发生重排指令重排主要反映在读和写的过程中</strong></p><p><strong>不会发生重排</strong></p><p>名称        代码示例            说明</p><p>写后读     a = 1;b = a;     写一个变量之后，再读这个位置。</p><p>写后写     a = 1;a = 2;     写一个变量之后，再写这个变量。</p><p>读后写     a = b;b = 1;     读一个变量之后，再写这个变量</p><p><strong>指令重排序规则</strong></p><p>在计算机执行指令的顺序在经过程序编译器编译之后形成的指令序列</p><p>一般而言，这个指令序列是会输出确定的结果；以确保每一次的执行都有确定的结果</p><p>但是，一般情况下，CPU和编译器为了提升程序执行的效率，会按照一定的规则允许进行指令优化<br>在某些情况下，这种优化会带来一些执行的逻辑问题，主要的原因是代码逻辑之间是存在一定的先后顺序</p><p>在并发执行情况下，会发生二义性，即按照不同的执行逻辑，会得到不同的结果信息。</p><p><strong>Happens-Before</strong></p><p><strong>程序次序规则</strong>：在一个线程内一段代码的执行结果是有序的。就是还会指令重排，但是随便它怎么排，结果是按照我们代码的顺序生成的不会变。<br><strong>管程锁定规则</strong>：就是无论是在单线程环境还是多线程环境，对于同一个锁来说，一个线程对这个锁解锁之后，另一个线程获取了这个锁都能看到前一个线程的操作结果！(管程是一种通用的同步原语，synchronized就是管程的实现）<br><strong>volatile变量规则</strong>：就是如果一个线程先去写一个volatile变量，然后一个线程去读这个变量，那么这个写操作的结果一定对读的这个线程可见。<br><strong>线程启动规则</strong>：在主线程A执行过程中，启动子线程B，那么线程A在启动子线程B之前对共享变量的修改结果对线程B见。<br><strong>线程终止规则</strong>：在主线程A执行过程中，子线程B终止，那么线程B在终止之前对共享变量的修改结果在线程A中可见。也称线程join()规则。<br><strong>线程中断规则</strong>：对线程interrupt()方法的调用先行发生于被中断线程代码检测到中断事件的发生，可以通过Thread.interrupted()检测到是否发生中断。<br><strong>传递性规则</strong>：这个简单的，就是happens-before原则具有传递性，即hb(A, B) ， hb(B, C)，那么hb(A, C)。<br><strong>对象终结规则</strong>：这个也简单的，就是一个对象的初始化的完成，也就是构造函</p><p><strong>内存屏障</strong></p><p><strong>实际上就是如果CPU在指令优化时给与一个标记位置，碰到此位置不进行优化</strong></p><p>Store：将处理器缓存的数据刷新到内存中。<br>Load：将内存存储的数据拷贝到处理器的缓存中。</p><img src="/2022/11/23/JMM内存模型与线程并发/image-20221123082200922.png" title="[JMM内存模型与线程并发]">]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;多核并发缓存架构解析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CPU 核心数和线程数的关系&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多核心:也指单芯片多处理器( Chip Multiprocessors,简称 CMP),CMP 是由美国斯坦福大学提出的,其思
      
    
    </summary>
    
    
      <category term="JUC" scheme="http://www.yppcat.top/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>JVM指令手册</title>
    <link href="http://www.yppcat.top/2022/11/20/JVM%E6%8C%87%E4%BB%A4%E6%89%8B%E5%86%8C/"/>
    <id>http://www.yppcat.top/2022/11/20/JVM指令手册/</id>
    <published>2022-11-20T13:30:37.000Z</published>
    <updated>2022-11-20T13:32:44.679Z</updated>
    
    <content type="html"><![CDATA[<h3 id="JVM指令手册"><a href="#JVM指令手册" class="headerlink" title="JVM指令手册"></a>JVM指令手册</h3><p>## 一、栈和局部变量操作</p><p>### 将常量压入栈的指令</p><p>aconst_null 将null对象引用压入栈</p><p>iconst_m1 将int类型常量-1压入栈</p><p>iconst_0 将int类型常量0压入栈</p><p>iconst_1 将int类型常量1压入栈</p><p>iconst_2 将int类型常量2压入栈</p><p>iconst_3 将int类型常量3压入栈</p><p>iconst_4 将int类型常量4压入栈</p><p>iconst_5 将int类型常量5压入栈</p><p>lconst_0 将long类型常量0压入栈</p><p>lconst_1 将long类型常量1压入栈</p><p>fconst_0 将float类型常量0压入栈</p><p>fconst_1 将float类型常量1压入栈</p><p>dconst_0 将double类型常量0压入栈</p><p>dconst_1 将double类型常量1压入栈</p><p>bipush 将一个8位带符号整数压入栈</p><p>sipush 将16位带符号整数压入栈</p><p>ldc 把常量池中的项压入栈</p><p>ldc_w 把常量池中的项压入栈（使用宽索引）</p><p>ldc2_w 把常量池中long类型或者double类型的项压入栈（使用宽索引）</p><p>### 从栈中的局部变量中装载值的指令</p><p>iload 从局部变量中装载int类型值</p><p>lload 从局部变量中装载long类型值</p><p>fload 从局部变量中装载float类型值</p><p>dload 从局部变量中装载double类型值</p><p>aload 从局部变量中装载引用类型值（refernce）</p><p>iload_0 从局部变量0中装载int类型值</p><p>iload_1 从局部变量1中装载int类型值</p><p>iload_2 从局部变量2中装载int类型值</p><p>iload_3 从局部变量3中装载int类型值</p><p>lload_0 从局部变量0中装载long类型值</p><p>lload_1 从局部变量1中装载long类型值</p><p>lload_2 从局部变量2中装载long类型值</p><p>lload_3 从局部变量3中装载long类型值</p><p>fload_0 从局部变量0中装载float类型值</p><p>fload_1 从局部变量1中装载float类型值</p><p>fload_2 从局部变量2中装载float类型值</p><p>fload_3 从局部变量3中装载float类型值</p><p>dload_0 从局部变量0中装载double类型值</p><p>dload_1 从局部变量1中装载double类型值</p><p>dload_2 从局部变量2中装载double类型值</p><p>dload_3 从局部变量3中装载double类型值</p><p>aload_0 从局部变量0中装载引用类型值</p><p>aload_1 从局部变量1中装载引用类型值</p><p>aload_2 从局部变量2中装载引用类型值</p><p>aload_3 从局部变量3中装载引用类型值</p><p>iaload 从数组中装载int类型值</p><p>laload 从数组中装载long类型值</p><p>faload 从数组中装载float类型值</p><p>daload 从数组中装载double类型值</p><p>aaload 从数组中装载引用类型值</p><p>baload 从数组中装载byte类型或boolean类型值</p><p>caload 从数组中装载char类型值</p><p>saload 从数组中装载short类型值</p><p>### 将栈中的值存入局部变量的指令</p><p>istore 将int类型值存入局部变量</p><p>lstore 将long类型值存入局部变量</p><p>fstore 将float类型值存入局部变量</p><p>dstore 将double类型值存入局部变量</p><p>astore 将将引用类型或returnAddress类型值存入局部变量</p><p>istore_0 将int类型值存入局部变量0</p><p>istore_1 将int类型值存入局部变量1</p><p>istore_2 将int类型值存入局部变量2</p><p>istore_3 将int类型值存入局部变量3</p><p>lstore_0 将long类型值存入局部变量0</p><p>lstore_1 将long类型值存入局部变量1</p><p>lstore_2 将long类型值存入局部变量2</p><p>lstore_3 将long类型值存入局部变量3</p><p>fstore_0 将float类型值存入局部变量0</p><p>fstore_1 将float类型值存入局部变量1</p><p>fstore_2 将float类型值存入局部变量2</p><p>fstore_3 将float类型值存入局部变量3</p><p>dstore_0 将double类型值存入局部变量0</p><p>dstore_1 将double类型值存入局部变量1</p><p>dstore_2 将double类型值存入局部变量2</p><p>dstore_3 将double类型值存入局部变量3</p><p>astore_0 将引用类型或returnAddress类型值存入局部变量0</p><p>astore_1 将引用类型或returnAddress类型值存入局部变量1</p><p>astore_2 将引用类型或returnAddress类型值存入局部变量2</p><p>astore_3 将引用类型或returnAddress类型值存入局部变量3</p><p>iastore 将int类型值存入数组中</p><p>lastore 将long类型值存入数组中</p><p>fastore 将float类型值存入数组中</p><p>dastore 将double类型值存入数组中</p><p>aastore 将引用类型值存入数组中</p><p>bastore 将byte类型或者boolean类型值存入数组中</p><p>castore 将char类型值存入数组中</p><p>sastore 将short类型值存入数组中</p><p>wide指令</p><p>wide 使用附加字节扩展局部变量索引</p><p>### 通用(无类型）栈操作</p><p>nop 不做任何操作</p><p>pop 弹出栈顶端一个字长的内容</p><p>pop2 弹出栈顶端两个字长的内容</p><p>dup 复制栈顶部一个字长内容</p><p>dup_x1 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的两个字长的内容压入栈</p><p>dup_x2 复制栈顶部一个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈</p><p>dup2 复制栈顶部两个字长内容</p><p>dup2_x1 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的三个字长的内容压入栈</p><p>dup2_x2 复制栈顶部两个字长的内容，然后将复制内容及原来弹出的四个字长的内容压入栈</p><p>swap 交换栈顶部两个字长内容</p><p>## 二、类型转换</p><p>i2l 把int类型的数据转化为long类型</p><p>i2f 把int类型的数据转化为float类型</p><p>i2d 把int类型的数据转化为double类型</p><p>l2i 把long类型的数据转化为int类型</p><p>l2f 把long类型的数据转化为float类型</p><p>l2d 把long类型的数据转化为double类型</p><p>f2i 把float类型的数据转化为int类型</p><p>f2l 把float类型的数据转化为long类型</p><p>f2d 把float类型的数据转化为double类型</p><p>d2i 把double类型的数据转化为int类型</p><p>d2l 把double类型的数据转化为long类型</p><p>d2f 把double类型的数据转化为float类型</p><p>i2b 把int类型的数据转化为byte类型</p><p>i2c 把int类型的数据转化为char类型</p><p>i2s 把int类型的数据转化为short类型</p><p>## 三、整数运算</p><p>iadd 执行int类型的加法</p><p>ladd 执行long类型的加法</p><p>isub 执行int类型的减法</p><p>lsub 执行long类型的减法</p><p>imul 执行int类型的乘法</p><p>lmul 执行long类型的乘法</p><p>idiv 执行int类型的除法</p><p>ldiv 执行long类型的除法</p><p>irem 计算int类型除法的余数</p><p>lrem 计算long类型除法的余数</p><p>ineg 对一个int类型值进行取反操作</p><p>lneg 对一个long类型值进行取反操作</p><p>iinc 把一个常量值加到一个int类型的局部变量上</p><p>## 四、逻辑运算</p><p>### 移位操作</p><p>ishl 执行int类型的向左移位操作</p><p>lshl 执行long类型的向左移位操作</p><p>ishr 执行int类型的向右移位操作</p><p>lshr 执行long类型的向右移位操作</p><p>iushr 执行int类型的向右逻辑移位操作</p><p>lushr 执行long类型的向右逻辑移位操作</p><p>### 按位布尔运算</p><p>iand 对int类型值进行“逻辑与”操作</p><p>land 对long类型值进行“逻辑与”操作</p><p>ior 对int类型值进行“逻辑或”操作</p><p>lor 对long类型值进行“逻辑或”操作</p><p>ixor 对int类型值进行“逻辑异或”操作</p><p>lxor 对long类型值进行“逻辑异或”操作</p><p>### 浮点运算</p><p>fadd 执行float类型的加法</p><p>dadd 执行double类型的加法</p><p>fsub 执行float类型的减法</p><p>dsub 执行double类型的减法</p><p>fmul 执行float类型的乘法</p><p>dmul 执行double类型的乘法</p><p>fdiv 执行float类型的除法</p><p>ddiv 执行double类型的除法</p><p>frem 计算float类型除法的余数</p><p>drem 计算double类型除法的余数</p><p>fneg 将一个float类型的数值取反</p><p>dneg 将一个double类型的数值取反</p><p>## 五、对象和数组</p><p>### 对象操作指令</p><p>new 创建一个新对象</p><p>checkcast 确定对象为所给定的类型。后跟目标类，判断栈顶元素是否为目标类 / 接口的实例。如果不是便抛出异常</p><p>getfield 从对象中获取字段</p><p>putfield 设置对象中字段的值</p><p>getstatic 从类中获取静态字段</p><p>putstatic 设置类中静态字段的值</p><p>instanceof 判断对象是否为给定的类型。后跟目标类，判断栈顶元素是否为目标类 / 接口的实例。是则压入 1，否则压入 0</p><p>### 数组操作指令</p><p>newarray 分配数据成员类型为基本上数据类型的新数组</p><p>anewarray 分配数据成员类型为引用类型的新数组</p><p>arraylength 获取数组长度</p><p>multianewarray 分配新的多维数组</p><p>## 六、控制流</p><p>### 条件分支指令</p><p>ifeq 如果等于0，则跳转</p><p>ifne 如果不等于0，则跳转</p><p>iflt 如果小于0，则跳转</p><p>ifge 如果大于等于0，则跳转</p><p>ifgt 如果大于0，则跳转</p><p>ifle 如果小于等于0，则跳转</p><p>if_icmpcq 如果两个int值相等，则跳转</p><p>if_icmpne 如果两个int类型值不相等，则跳转</p><p>if_icmplt 如果一个int类型值小于另外一个int类型值，则跳转</p><p>if_icmpge 如果一个int类型值大于或者等于另外一个int类型值，则跳转</p><p>if_icmpgt 如果一个int类型值大于另外一个int类型值，则跳转</p><p>if_icmple 如果一个int类型值小于或者等于另外一个int类型值，则跳转</p><p>ifnull 如果等于null，则跳转</p><p>ifnonnull 如果不等于null，则跳转</p><p>if_acmpeq 如果两个对象引用相等，则跳转</p><p>if_acmpnc 如果两个对象引用不相等，则跳转</p><p>### 比较指令</p><p>lcmp 比较long类型值</p><p>fcmpl 比较float类型值（当遇到NaN时，返回-1）</p><p>fcmpg 比较float类型值（当遇到NaN时，返回1）</p><p>dcmpl 比较double类型值（当遇到NaN时，返回-1）</p><p>dcmpg 比较double类型值（当遇到NaN时，返回1）</p><p>### 无条件转移指令</p><p>goto 无条件跳转</p><p>goto_w 无条件跳转（宽索引）</p><p>### 表跳转指令</p><p>tableswitch 通过索引访问跳转表，并跳转</p><p>lookupswitch 通过键值匹配访问跳转表，并执行跳转操作</p><p>### 异常</p><p>athrow 抛出异常或错误。将栈顶异常抛出</p><p>finally子句</p><p>jsr 跳转到子例程</p><p>jsr_w 跳转到子例程（宽索引）</p><p>rct 从子例程返回</p><p>## 七、方法调用与返回</p><p>### 方法调用指令</p><p>invokcvirtual 运行时按照对象的类来调用实例方法</p><p>invokespecial 根据编译时类型来调用实例方法</p><p>invokestatic 调用类（静态）方法</p><p>invokcinterface 调用接口方法</p><p>### 方法返回指令</p><p>ireturn 从方法中返回int类型的数据</p><p>lreturn 从方法中返回long类型的数据</p><p>freturn 从方法中返回float类型的数据</p><p>dreturn 从方法中返回double类型的数据</p><p>areturn 从方法中返回引用类型的数据</p><p>return 从方法中返回，返回值为void</p><p>### 线程同步</p><p>montiorenter 进入并获取对象监视器。即：为栈顶对象加锁</p><p>monitorexit 释放并退出对象监视器。即：为栈顶对象解锁</p><p>## 八、JVM指令助记符</p><p>变量到操作数栈：iload,iload_,lload,lload_,fload,fload_,dload,dload_,aload,aload_</p><p>操作数栈到变量：istore,istore_,lstore,lstore_,fstore,fstore_,dstore,dstor_,astore,astore_</p><p>常数到操作数栈：bipush,sipush,ldc,ldc_w,ldc2_w,aconst_null,iconst_ml,iconst_,lconst_,fconst_,dconst_</p><p>加：iadd,ladd,fadd,dadd</p><p>减：isub,lsub,fsub,dsub</p><p>乘：imul,lmul,fmul,dmul</p><p>除：idiv,ldiv,fdiv,ddiv</p><p>余数：irem,lrem,frem,drem</p><p>取负：ineg,lneg,fneg,dneg</p><p>移位：ishl,lshr,iushr,lshl,lshr,lushr</p><p>按位或：ior,lor</p><p>按位与：iand,land</p><p>按位异或：ixor,lxor</p><p>类型转换：i2l,i2f,i2d,l2f,l2d,f2d(放宽数值转换)</p><p>i2b,i2c,i2s,l2i,f2i,f2l,d2i,d2l,d2f(缩窄数值转换)</p><p>创建类实便：new</p><p>创建新数组：newarray,anewarray,multianwarray</p><p>访问类的域和类实例域：getfield,putfield,getstatic,putstatic</p><p>把数据装载到操作数栈：baload,caload,saload,iaload,laload,faload,daload,aaload</p><p>从操作数栈存存储到数组：bastore,castore,sastore,iastore,lastore,fastore,dastore,aastore</p><p>获取数组长度：arraylength</p><p>检相类实例或数组属性：instanceof,checkcast</p><p>操作数栈管理：pop,pop2,dup,dup2,dup_xl,dup2_xl,dup_x2,dup2_x2,swap</p><p>有条件转移：ifeq,iflt,ifle,ifne,ifgt,ifge,ifnull,ifnonnull,if_icmpeq,if_icmpene,</p><p>if_icmplt,if_icmpgt,if_icmple,if_icmpge,if_acmpeq,if_acmpne,lcmp,fcmpl</p><p>fcmpg,dcmpl,dcmpg</p><p>复合条件转移：tableswitch,lookupswitch</p><p>无条件转移：goto,goto_w,jsr,jsr_w,ret</p><p>调度对象的实便方法：invokevirtual</p><p>调用由接口实现的方法：invokeinterface</p><p>调用需要特殊处理的实例方法：invokespecial</p><p>调用命名类中的静态方法：invokestatic</p><p>方法返回：ireturn,lreturn,freturn,dreturn,areturn,return</p><p>异常：athrow</p><p>finally关键字的实现使用：jsr,jsr_w,ret</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;JVM指令手册&quot;&gt;&lt;a href=&quot;#JVM指令手册&quot; class=&quot;headerlink&quot; title=&quot;JVM指令手册&quot;&gt;&lt;/a&gt;JVM指令手册&lt;/h3&gt;&lt;p&gt;## 一、栈和局部变量操作&lt;/p&gt;
&lt;p&gt;### 将常量压入栈的指令&lt;/p&gt;
&lt;p&gt;aconst_n
      
    
    </summary>
    
    
      <category term="JVM" scheme="http://www.yppcat.top/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>class字节码文件结构</title>
    <link href="http://www.yppcat.top/2022/11/20/class%E5%AD%97%E8%8A%82%E7%A0%81%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/"/>
    <id>http://www.yppcat.top/2022/11/20/class字节码文件结构/</id>
    <published>2022-11-20T13:30:19.000Z</published>
    <updated>2022-11-20T13:32:28.054Z</updated>
    
    <content type="html"><![CDATA[<h3 id="class字节码文件结构"><a href="#class字节码文件结构" class="headerlink" title="class字节码文件结构"></a>class字节码文件结构</h3><p>## class字节码文件结构</p><p>| 类型      | 名称        | 说明          | 长度  | 数量         |</p><p>| ————– | ——————- | ———————- | ——- | ——————— |</p><p>| u4       | magic        | 魔数,识别Class文件格式 | 4个字节 | 1           |</p><p>| u2       | minor_version    | 副版本号(小版本)    | 2个字节 | 1           |</p><p>| u2       | major_version    | 主版本号(大版本)    | 2个字节 | 1           |</p><p>| u2       | constant_pool_count | 常量池计数器      | 2个字节 | 1           |</p><p>| cp_info    | constant_pool    | 常量池表        | n个字节 | constant_pool_count-1 |</p><p>| u2       | access_flags    | 访问标识        | 2个字节 | 1           |</p><p>| u2       | this_class     | 类索引         | 2个字节 | 1           |</p><p>| u2       | super_class     | 父类索引        | 2个字节 | 1           |</p><p>| u2       | interfaces_count  | 接口计数器       | 2个字节 | 1           |</p><p>| u2       | interfaces     | 接口索引集合      | 2个字节 | interfaces_count   |</p><p>| u2       | fields_count    | 字段计数器       | 2个字节 | 1           |</p><p>| field_info   | fields       | 字段表         | n个字节 | fields_count     |</p><p>| u2       | methods_count    | 方法计数器       | 2个字节 | 1           |</p><p>| method_info  | methods       | 方法表         | n个字节 | methods_count     |</p><p>| u2       | attributes_count  | 属性计数器       | 2个字节 | 1           |</p><p>| attribute_info | attributes     | 属性表         | n个字节 | attributes_count   |</p><p>## Class文件版本号和平台的对应</p><p>| 主版本（十进制） | 副版本（十进制） | 编译器版本 |</p><p>| —————- | —————- | ———- |</p><p>| 45        | 3        | 1.1    |</p><p>| 46        | 0        | 1.2    |</p><p>| 47        | 0        | 1.3    |</p><p>| 48        | 0        | 1.4    |</p><p>| 49        | 0        | 1.5    |</p><p>| 50        | 0        | 1.6    |</p><p>| 51        | 0        | 1.7    |</p><p>| 52        | 0        | 1.8    |</p><p>| 53        | 0        | 1.9    |</p><p>| 54        | 0        | 1.10    |</p><p>| 55        | 0        | 1.11    |</p><p>## class文件数据类型</p><p>| 数据类型 | 定义                             | 说明                             |</p><p>| ——– | ———————————————————— | ———————————————————— |</p><p>| 无符号数 | 无符号数可以用来描述数字、索引引用、数量值或按照utf-8编码构成的字符串值。 | 其中无符号数属于基本的数据类型。 以u1、u2、u4、u8来分别代表1个字节、2个字节、4个字节和8个字节 |</p><p>| 表    | 表是由多个无符号数或其他表构成的复合数据结构。        | 所有的表都以“_info”结尾。 由于表没有固定长度，所以通常会在其前面加上个数说明。 |</p><p>## 类型描述符</p><p>| 标志符 | 含义                         |</p><p>| —— | —————————————————- |</p><p>| B   | 基本数据类型byte                   |</p><p>| C   | 基本数据类型char                   |</p><p>| D   | 基本数据类型double                  |</p><p>| F   | 基本数据类型float                  |</p><p>| I   | 基本数据类型int                   |</p><p>| J   | 基本数据类型long                   |</p><p>| S   | 基本数据类型short                  |</p><p>| Z   | 基本数据类型boolean                 |</p><p>| V   | 代表void类型                     |</p><p>| L   | 对象类型，比如：<code>Ljava/lang/Object;</code>         |</p><p>| [   | 数组类型，代表一维数组。比如：<code>double[][][] is [[[D</code> |</p><p>## 常量类型和结构</p><p>| 类型               | 标志(或标识) | 描述          |</p><p>| ——————————– | ———— | ———————- |</p><p>| CONSTANT_utf8_info        | 1      | UTF-8编码的字符串   |</p><p>| CONSTANT_Integer_info      | 3      | 整型字面量       |</p><p>| CONSTANT_Float_info       | 4      | 浮点型字面量      |</p><p>| CONSTANT_Long_info        | 5      | 长整型字面量      |</p><p>| CONSTANT_Double_info       | 6      | 双精度浮点型字面量   |</p><p>| CONSTANT_Class_info       | 7      | 类或接口的符号引用   |</p><p>| CONSTANT_String_info       | 8      | 字符串类型字面量    |</p><p>| CONSTANT_Fieldref_info      | 9      | 字段的符号引用     |</p><p>| CONSTANT_Methodref_info     | 10      | 类中方法的符号引用   |</p><p>| CONSTANT_InterfaceMethodref_info | 11      | 接口中方法的符号引用  |</p><p>| CONSTANT_NameAndType_info    | 12      | 字段或方法的符号引用  |</p><p>| CONSTANT_MethodHandle_info    | 15      | 表示方法句柄      |</p><p>| CONSTANT_MethodType_info     | 16      | 标志方法类型      |</p><p>| CONSTANT_InvokeDynamic_info   | 18      | 表示一个动态方法调用点 |</p><p>## 常量类型和结构细节</p><table><thead><tr><th>常量类型和结构</th><th></th><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td>标志</td><td>常量</td><td>描述</td><td>细节</td><td>长度</td><td>细节描述</td></tr><tr><td>1</td><td>CONSTANT_utf8_info</td><td>UTF-8编码的字符串</td><td>tag</td><td>u1</td><td>值为1</td></tr><tr><td>length</td><td>u2</td><td>UTF-8编码的字符串占用的字符数</td><td></td><td></td><td></td></tr><tr><td>bytes</td><td>u1</td><td>长度为length的UTF-8编码的字符串</td><td></td><td></td><td></td></tr><tr><td>3</td><td>CONSTANT_Integer_info</td><td>整型字面量</td><td>tag</td><td>u1</td><td>值为3</td></tr><tr><td>bytes</td><td>u4</td><td>按照高位在前存储的int值</td><td></td><td></td><td></td></tr><tr><td>4</td><td>CONSTANT_Float_info</td><td>浮点型字面量</td><td>tag</td><td>u1</td><td>值为4</td></tr><tr><td>bytes</td><td>u4</td><td>按照高位在前存储的float值</td><td></td><td></td><td></td></tr><tr><td>5</td><td>CONSTANT_Long_info</td><td>长整型字面量</td><td>tag</td><td>u1</td><td>值为5</td></tr><tr><td>bytes</td><td>u8</td><td>按照高位在前存储的long值</td><td></td><td></td><td></td></tr><tr><td>6</td><td>CONSTANT_Double_info</td><td>双精度浮点型字面量</td><td>tag</td><td>u1</td><td>值为6</td></tr><tr><td>bytes</td><td>u8</td><td>按照高位在前存储的double值</td><td></td><td></td><td></td></tr><tr><td>7</td><td>CONSTANT_Class_info</td><td>类或接口的符号引用</td><td>tag</td><td>u1</td><td>值为7</td></tr><tr><td>index</td><td>u2</td><td>指向全限定名常量项的索引</td><td></td><td></td><td></td></tr><tr><td>8</td><td>CONSTANT_String_info</td><td>字符串类型字面量</td><td>tag</td><td>u1</td><td>值为8</td></tr><tr><td>index</td><td>u2</td><td>指向字符串字面量的索引</td><td></td><td></td><td></td></tr><tr><td>9</td><td>CONSTANT_Fieldref_info</td><td>字段的符号引用</td><td>tag</td><td>u1</td><td>值为9</td></tr><tr><td>index</td><td>u2</td><td>指向声明字段的类或接口描述符CONSTANT_Class_info的索引项</td><td></td><td></td><td></td></tr><tr><td>index</td><td>u2</td><td>指向字段描述符CONSTANT_NameAndType的索引项</td><td></td><td></td><td></td></tr><tr><td>10</td><td>CONSTANT_Methodref_info</td><td>类中方法的符号引用</td><td>tag</td><td>u1</td><td>值为10</td></tr><tr><td>index</td><td>u2</td><td>指向声明方法的类描述符CONSTANT_Class_Info的索引项</td><td></td><td></td><td></td></tr><tr><td>index</td><td>u2</td><td>指向名称及类型描述符CONSTANT_NameAndType的索引项</td><td></td><td></td><td></td></tr><tr><td>11</td><td>CONSTANT_InterfaceMethodref_info</td><td>接口中方法的符号引用</td><td>tag</td><td>u1</td><td>值为11</td></tr><tr><td>index</td><td>u2</td><td>指向声明方法的接口描述符CONSTANT_Class_Info的索引项</td><td></td><td></td><td></td></tr><tr><td>index</td><td>u2</td><td>指向名称及类型描述符CONSTANT_NameAndType的索引项</td><td></td><td></td><td></td></tr><tr><td>12</td><td>CONSTANT_NameAndType_info</td><td>字段或方法的符号引用</td><td>tag</td><td>u1</td><td>值为12</td></tr><tr><td>index</td><td>u2</td><td>指向该字段或方法名称常量项的索引</td><td></td><td></td><td></td></tr><tr><td>index</td><td>u2</td><td>指向该字段或方法描述符常量项的索引</td><td></td><td></td><td></td></tr><tr><td>15</td><td>CONSTANT_MethodHandle_info</td><td>表示方法句柄</td><td>tag</td><td>u1</td><td>值为15</td></tr><tr><td>reference_kind</td><td>u1</td><td>值必须在1-9之间，它决定了方法句柄的类型方法句柄类型的值表示方法句柄的字节码行为</td><td></td><td></td><td></td></tr><tr><td>reference_index</td><td>u2</td><td>值必须是对常量池的有效索引</td><td></td><td></td><td></td></tr><tr><td>16</td><td>CONSTANT_MethodType_info</td><td>标志方法类型</td><td>tag</td><td>u1</td><td>值为16</td></tr><tr><td>descriptor_index</td><td>u2</td><td>值必须是对常量池的有效索引，常量池在该索引处的项必须是CONSTANT_Utf8_info结构，表示方法的描述符</td><td></td><td></td><td></td></tr><tr><td>18</td><td>CONSTANT_InvokeDynamic_info</td><td>表示一个动态方法调用点</td><td>tag</td><td>u1</td><td>值为18</td></tr><tr><td>bootstrap_method_attr</td><td>u2</td><td>值必须是对当前Class文件中引导方法表的bootstrap_methods[]数组的有效索引</td><td></td><td></td><td></td></tr><tr><td>name_and_type_index</td><td>u2</td><td>值必须是对当前常量池的有效索引，常量池在该索引处的项必须是CONSTANT_NameAndType_Info结构，表示方法名和方法描述符</td><td></td><td></td></tr></tbody></table><p>## 访问标志</p><p>| 标志名称    | 标志值 | 含义                             |</p><p>| ————– | —— | ———————————————————— |</p><p>| ACC_PUBLIC   | 0x0001 | 标志为public类型                       |</p><p>| ACC_FINAL   | 0x0010 | 标志被声明为final，只有类可以设置              |</p><p>| ACC_SUPER   | 0x0020 | 标志允许使用invokespecial字节码指令的新语义，JDK1.0.2之后编译出来的类的这个标志默认为真。（使用增强的方法调用父类方法） |</p><p>| ACC_INTERFACE | 0x0200 | 标志这是一个接口                       |</p><p>| ACC_ABSTRACT  | 0x0400 | 是否为abstract类型，对于接口或者抽象类来说，次标志值为真，其他类型为假 |</p><p>| ACC_SYNTHETIC | 0x1000 | 标志此类并非由用户代码产生（即：由编译器产生的类，没有源码对应） |</p><p>| ACC_ANNOTATION | 0x2000 | 标志这是一个注解                       |</p><p>| ACC_ENUM    | 0x4000 | 标志这是一个枚举                       |</p><p>## 字段表访问标志</p><p>| 标志名称   | 标志值 | 含义            |</p><p>| ————- | —— | ————————– |</p><p>| ACC_PUBLIC  | 0x0001 | 字段是否为public      |</p><p>| ACC_PRIVATE  | 0x0002 | 字段是否为private     |</p><p>| ACC_PROTECTED | 0x0004 | 字段是否为protected    |</p><p>| ACC_STATIC  | 0x0008 | 字段是否为static      |</p><p>| ACC_FINAL   | 0x0010 | 字段是否为final      |</p><p>| ACC_VOLATILE | 0x0040 | 字段是否为volatile     |</p><p>| ACC_TRANSTENT | 0x0080 | 字段是否为transient    |</p><p>| ACC_SYNCHETIC | 0x1000 | 字段是否为由编译器自动产生 |</p><p>| ACC_ENUM   | 0x4000 | 字段是否为enum       |</p><p>## 类索引、父类索引、接口索引</p><p>| 长度 | 含义             |</p><p>| —- | —————————- |</p><p>| u2  | this_class          |</p><p>| u2  | super_class         |</p><p>| u2  | interfaces_count       |</p><p>| u2  | interfaces[interfaces_count] |</p><p>## 属性的通用格式</p><p>| 类型 | 名称         | 数量       | 含义    |</p><p>| —- | ——————– | —————- | ———- |</p><p>| u2  | attribute_name_index | 1        | 属性名索引 |</p><p>| u4  | attribute_length   | 1        | 属性长度  |</p><p>| u1  | info         | attribute_length | 属性表   |</p><p>## 数据类型和默认初始值对应</p><p>| 类型   | 默认初始值 |</p><p>| ——— | ———- |</p><p>| byte   | (byte)0  |</p><p>| short   | (short)0  |</p><p>| int    | 0     |</p><p>| long   | 0L     |</p><p>| float   | 0.0f    |</p><p>| double  | 0.0    |</p><p>| char   | \u0000   |</p><p>| boolean  | false   |</p><p>| reference | null    |</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;class字节码文件结构&quot;&gt;&lt;a href=&quot;#class字节码文件结构&quot; class=&quot;headerlink&quot; title=&quot;class字节码文件结构&quot;&gt;&lt;/a&gt;class字节码文件结构&lt;/h3&gt;&lt;p&gt;## class字节码文件结构&lt;/p&gt;
&lt;p&gt;| 类型   
      
    
    </summary>
    
    
      <category term="JVM" scheme="http://www.yppcat.top/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>字节码文件与类加载</title>
    <link href="http://www.yppcat.top/2022/11/20/%E5%AD%97%E8%8A%82%E7%A0%81%E6%96%87%E4%BB%B6%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD/"/>
    <id>http://www.yppcat.top/2022/11/20/字节码文件与类加载/</id>
    <published>2022-11-20T13:11:06.000Z</published>
    <updated>2022-11-20T13:48:32.227Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Dalvik虚拟机</strong>执行的是dex字节码，解释执行。从Android 2.2版本开始，支持在程序运行的过程中进行选择热点代码（经常执行的代码）进行编译或者优化。</p><p>而<strong>ART（Android Runtime）</strong> 是在 Android 4.4 中引入的一个开发者选项，也是 Android 5.0 及更高版本的默认 Android 运行时。<strong>ART虚拟机执行的是本地机器码</strong>。Android的运行时从Dalvik虚拟机替换成ART虚拟机，并不要求开发者将自己的应用直接编译成目标机器码，APK仍然是一个包含dex字节码的文件。 </p><p><strong>那么，ART虚拟机执行的本地机器码是从哪里来？</strong></p><p><strong>前端编译器与后端编译器</strong></p><img src="/2022/11/20/字节码文件与类加载/image-20221120211238030.png" title="[字节码文件与类加载]"><p><strong>解释执行&amp;JIT&amp;AOT</strong></p><p>解释执行 ： 程序运行过程中，逐行进行代码编译</p><p>JIT ：程序运行过程中，将热点代码进行编译缓存执行</p><p>AOT：运行之前，将所有代码打包编译成机器码</p><p><strong>dex2aot</strong></p><p>Dalvik下应用在安装的过程，会执行一次优化，将dex字节码进行优化生成odex文件。</p><p>而Art下将应用的dex字节码翻译成本地机器码的最恰当AOT时机也就发生在应用安装的时候。ART 引入了预先编译机制（Ahead Of Time），在安装时，ART 使用设备自带的 dex2oat 工具来编译应用，dex中的字节码将被编译成本地机器码</p><img src="/2022/11/20/字节码文件与类加载/image-20221120211537989.png" title="[字节码文件与类加载]"><p><strong>Android N的运作方式</strong></p><p>ART 使用预先 (AOT) 编译，并且从 Android N混合使用AOT编译，解释和JIT。</p><p>1、最初安装应用时不进行任何 AOT 编译（安装又快了），运行过程中解释执行，对经常执行的方法进行JIT，经过 JIT 编译的方法将会记录到<strong>Profile</strong>配置文件中。</p><p>2、当设备闲置和充电时，编译守护进程会运行，根据<strong>Profile</strong>文件对常用代码进行 AOT 编译。待下次运行时直接使用。</p><p><strong>“类（文件）”的生命周期</strong></p><p><strong>类的生命周期概述</strong></p><p>在JAVA中数据类型分为引用数据类型与基本数据类型，基本数据类型由虚拟机预先定义，引用数据类型则需要进行类加载。</p><p>按照JAVA虚拟机规范，从class文件到加载到内存当中的类，到类写在出内存位置，他的整个生命周期包含下述七个阶段</p><img src="/2022/11/20/字节码文件与类加载/image-20221120211738049.png" title="[字节码文件与类加载]"><img src="/2022/11/20/字节码文件与类加载/“类”的生命周期.png" title="[字节码文件与类加载]"><p>类的卸载</p><img src="/2022/11/20/字节码文件与类加载/生命周期-类卸载.png" title="[字节码文件与类加载]"><p> 我们需要知道的是，一个我自己写的代码文件如何到内存当中被使用以及释放的过程</p><p>​       1.写代码—.java—&gt;前段编译器—&gt;.class—–&gt;通过IO读取进来—-&gt;解析文件结构，约定固定套路</p><p>​       —-&gt;将解出来的数据扔到方法区—-&gt;将当前这个类的信息提取出来—&gt;推到堆当中生成Class对象</p><p>​       —-&gt;具体使用—&gt;cinit—-&gt;卸载</p><p><strong>字节码解析</strong></p><img src="/2022/11/20/字节码文件与类加载/image-20221120213716176.png" title="[字节码文件与类加载]"><p><strong>类加载器</strong></p><img src="/2022/11/20/字节码文件与类加载/类加载器.png" title="[字节码文件与类加载]"><p>类加载：</p><p>​         读取指定目录下面的相关字节码文件，解析文</p><p>​           <strong>系统类加载器/启动类加载器/根类加载器</strong></p><p>​             加载jre下的内容</p><p>​            <strong>扩展类加载器</strong></p><p>​             加载ext文件夹下的内容</p><p>​           <strong>应用程序类加载器</strong></p><p>​             加载自己工程当中的内容</p><p>​           <strong>自定义类加载器（热修复）</strong></p><p>​             提供自己去写类加载器的方案，自己去指定某个路径或者某个文件，只要你是符合jvm字节码规范</p><p>​           Dex—&gt;N个Class文件—》应用程序类加载器–》不支持。自己写</p><p>​           </p><p>​           类加载器的分类=类加载器的种类</p><p>​             不是继承关系，每个人都是独立的，每个人干自己不同的活，加载代码的路径不一致   </p><p>​         ART ！= JVM</p><p>​         BootClassLoader—&gt;DexBaseClassloader</p><p>  <strong>Android的应用程序类加载器</strong></p><img src="/2022/11/20/字节码文件与类加载/image-20221120211910243.png" title="[字节码文件与类加载]"><p> 类加载–》物理读取字节码文件的动作</p><p>​           loadClass—》双亲委派–》为了保证我找不到，其他人能够去找</p><p>​           findClass—&gt;找一个路径，读取这个文件出来，形成一个字节码数组</p><p>​           defindClass—》将字节码文件读取完后进行校验，然后生成Class数据对象</p><p>​          </p><p>​           defindClass结束，类加载结束—-</p><p><strong>热修复原理</strong></p><p>热修复原理就是类加载器的核心</p><img src="/2022/11/20/字节码文件与类加载/image-20221120211930746.png" title="[字节码文件与类加载]"><p>热修复文章 ： <a href="https://blog.csdn.net/sahadev_/article/details/53318251" target="_blank" rel="noopener">https://blog.csdn.net/sahadev_/article/details/53318251</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;Dalvik虚拟机&lt;/strong&gt;执行的是dex字节码，解释执行。从Android 2.2版本开始，支持在程序运行的过程中进行选择热点代码（经常执行的代码）进行编译或者优化。&lt;/p&gt;
&lt;p&gt;而&lt;strong&gt;ART（Android Runtime）&lt;/st
      
    
    </summary>
    
    
      <category term="JVM" scheme="http://www.yppcat.top/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>GC及调优</title>
    <link href="http://www.yppcat.top/2022/11/18/GC%E5%8F%8A%E8%B0%83%E4%BC%98/"/>
    <id>http://www.yppcat.top/2022/11/18/GC及调优/</id>
    <published>2022-11-18T11:25:19.000Z</published>
    <updated>2022-11-18T11:54:40.354Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GC核心概述"><a href="#GC核心概述" class="headerlink" title="GC核心概述"></a><strong>GC核心概述</strong></h2><p><strong>Java自动化内存管理</strong></p><p>好处：<br>   无需开发人员手动参与内存分配与回收，降低内存泄漏与溢出风险</p><p>缺点：<br>   弱化了开发人员在程序出现内存溢出时定位问题和解决问题的能</p><p>对于我们现在的意义：<br>我们必须堆这些自动化技术的原理进行了解，学会如何去监控和调节</p><p><strong>垃圾</strong>：指在程序中没有任何指针指向的对象，这个对象就是需要被回收的垃圾</p><p><strong>内存碎片概念</strong></p><img src="/2022/11/18/GC及调优/image-20221118192853538.png" title="[GC及调优]"><p>存储地址空间是指对存储器编码（编码地址）的范围。所谓编码就是对每一个物理存储单元（一个字节）分配一个号码，通常叫作“编址”。分配一个号码给一个存储单元的目的是为了便于找到它，完成数据的读写，这就是所谓的“寻址”（所以，有人也把地址空间称为寻址空间）。<br>地址空间的大小和物理存储器的大小并不一定相等。举个例子来说明这个问题：某层楼共有17个房间，其编号为801～817。这17个房间是物理的，而其地址空间采用了三位编码，其范围是800～899共100个地址，可见地址空间是大于实际房间数量的。</p><p><strong>为什么需要GC？</strong></p><p>对于系统而言，内存迟早都会被消耗完，因为不断的分配内存空间而不进行回溯，就好像不停的产生生活垃圾</p><p>但是除了释放垃圾对象，也需要对于内存空间进行碎片管理，没有GC就不能保证应用程序的正常化进行</p><h5 id="GC核心算法"><a href="#GC核心算法" class="headerlink" title="GC核心算法"></a><strong>GC核心算法</strong></h5><p>1.<strong>垃圾确认算法</strong>–标记阶段算法<br>    引用计数算法<br>    GCRoot可达性分析算法<br>2.<strong>清除垃圾算法</strong>–清除阶段算法<br>    标记-清除算法<br>    复制算法<br>    标记-压缩算法</p><p><strong>引用计数算法</strong></p><p>原理：对每一个对象保存一个整形的引用计数器属性，用于记录对象被引用的情况。</p><p>例：一个对象A只要有任何一个对象引用了A则A的引用计数器就+1，当引用失效时，引用计数器就-1.只要对象A的引用计数器的值为0，即标识对象A不可能再被使用，可进行回收</p><p>优点：实现简单，垃圾对象便于识别，判断效率高</p><p>缺点：<br>    他需要单独的字段存储计数器，这样的做法增加的存储空间的开销<br>    每次赋值需要额外的加减法计算，增加了时间开销<br>    引用计数算法最大的问题是无法处理循环引用的情况，这是一个比较致命的缺陷</p><p>引用计数算法循环引用问题</p><img src="/2022/11/18/GC及调优/image-20221118193123263.png" title="[GC及调优]"><p><strong>可达性分析算法</strong></p><p>相对于引用计数算法，他有效的解决了在引用计数算法中的循环引用问题，防止内存泄漏发生<br>这种类型的垃圾收集也叫作追踪性垃圾收集</p><p>概念：</p><p>可达性分析算法以跟对象集合为起点，按照从上至下的方式搜索被跟对象集合所链接的对象目标是否可达</p><p>使用可达性分析算法后，内存中的存货对象会被跟对象集合直接或者间接连接着，搜索所走过的路径称之为引用链</p><p>如果目标对象没有任何阴影链项链，则是不可达的，意味着该对象已经死亡，可以标记为垃圾对象。</p><p>在可达性分析算法中只有能够被根对象集合直接或间接连接的对象才是存活对象。</p><img src="/2022/11/18/GC及调优/image-20221118193236025.png" title="[GC及调优]"><p><strong>GCRoots</strong></p><p>虚拟机栈汇总的引用对象<br>例：各个线程被调用的方法中使用的参数、局部变量等<br>本地方法栈内JNI引用的对象</p><p>方法区中类静态属性引用对象<br>例：JAVA类的引用类型静态变量</p><p>方法区中常量引用的对象<br>例：字符串常量池里面的引用</p><p>所有被同步所synchronize持有的对象</p><p>java虚拟机内部引用的对象<br>例：基本数据类型对应的Class对象，一些常驻的异常对象（NullPointerException等）,系统类加载器</p><p>总结：一个指针，他保存了堆里面的对象，但自己又不在堆当中，那么他就是一个Root</p><p><strong>标记-清除（Mark-Sweep）算法</strong></p><img src="/2022/11/18/GC及调优/image-20221118193411647.png" title="[GC及调优]"><p>背景：<br>标记清除算法是一种非常基础和常见的垃圾收集算法，该算法被J.McCarthy等人在1960年提出并应用于Lisp语言</p><p>执行过程：<br>当堆空间中有效内存空间被耗尽时，就会停止这个程序（Stop the world），然后进行两项工作，标记，清除这两部分<br><strong>标记</strong>：从引用根节点上开始遍历（可达性分析算法）标记所有被引用的对象。一般是在对象Header中记录为可达对象。<br><strong>清除</strong>：对堆内存从头到尾进行线性遍历，如果发现某个对象在其Header中没有标记为可达对象，则将其回收<br><strong>缺点</strong>：效率不高；在进行GC的时候需要停止整个应用程序，导致用户体验差；且会产生的大量的内存碎片</p><p>注意：<br>在这里的清除不是去干掉具体内存中的数据，而是本身分配的是一组连续的内存编码给我们使用，清除就是在回收这些空闲地址，将他们保存在空闲地址表当中，下次有新的对象需要空间时去判断是否够用</p><p><strong>复制（Copying）算法</strong></p><img src="/2022/11/18/GC及调优/image-20221118193546205.png" title="[GC及调优]"><p>背景：<br>为了解决标记-清除算法在垃圾收集效率方面的缺陷，M.LMinsky与1963年发表了著名论文，”使用双存储区的Lisp语言垃圾收集器“，该论文中被描述的算法被人们称之为复制算法。</p><p>执行过程：<br>将内存空间分为两块，每次只使用其中一块，在垃圾回收的时候，将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块，交换两个内存角色。<br>缺点：<br>1.需要两倍空间<br>2.GC需要维护对象的引用关系，时间开销加大<br>此种方案使用与垃圾对象较少，量级不大的情况</p><p>应用场景</p><p>在年青代中，对常规应用的垃圾回收，一次通常可以回收70%-99%的内存空间。回收性价比高。所以年青代一般采用这种</p><img src="/2022/11/18/GC及调优/image-20221118193633262.png" title="[GC及调优]"><p><strong>标记-压缩/整理（Mark-Compact）算法</strong></p><p>背景：<br>复制算法的高效是简历在存货对象少、垃圾对象多的前提下。这种情况在新生代中经常法神，但是在老年代，更常见的情况是大部分对象都是存货的。如果依然使用复制算法，由于存货对象多，复制成本也会非常高。因此基于老年代使用复制算法并不适用。</p><p>执行过程：<br>第一阶段与标记清除算法一致。<br>第二阶段将所有的存货对象压缩到内存的一段，按照顺讯排放，之后清理边界外所有空间</p><img src="/2022/11/18/GC及调优/image-20221118193809294.png" title="[GC及调优]"><p>优劣：<br>标记压缩算法的最终效果等同于标记-清除算法执行完成后在进行一次内存碎片的整理，因此，也可以把他称之为标记-清除-压缩（Mark-Sweep-Compact）算法。<br>二者本质差异在于标记清除算法是一直非移动式的回收算法，标记压缩是移动式的。是否移动回收后的存货对象是一项优缺点并存的风险决策<br>可以看到，标记的存货被整理后，按照内存地址一次排列，而未被标记的内存会被清理掉。如此一来，我们需要给新对象分配内存是，JVM只需要持有一个内存的起始地址即可，这个比维护一个空闲列表显然少了很多开销</p><p><strong>三种算法的性能指标对比</strong></p><table><thead><tr><th><strong>指标</strong></th><th><strong>Mark-Sweep</strong></th><th><strong>Mark-Compact</strong></th><th><strong>Copying</strong></th></tr></thead><tbody><tr><td>速度</td><td>中等</td><td>最慢</td><td>最快</td></tr><tr><td>空间</td><td>少（会堆积碎片）</td><td>少（不堆积碎片）</td><td>需要两倍大小（不堆积碎片）</td></tr><tr><td>移动对象</td><td>否</td><td>是</td><td>是</td></tr></tbody></table><p>效率上来说，复制算法最快，但是内存浪费最多<br>而为了尽量兼顾上面三个指标，标记整理算法相对平滑一些，但是效率上不仅如此任意，他比复制算法多了一个标记阶段，比清除多了一个整理内存阶段</p><p><strong>分代收集算法</strong></p><p>为了满足垃圾回收的效率最优性，所以分代手机算法应运而生。<br>分代手机算法基于一个事实：不同的对象生命周期是不一样的，因此，不同生命周期的对象可以采取不同的手机方式，以便于提高回收效率。一般是把JAVA堆分为<strong>新生代</strong>和<strong>老年代</strong>，这样就可以根据各个年代的特点使用不同回收算法，相对提高效率<br>在系统运行过程汇总，会产生大量对象，其中有些对象是业务信息相关，如HTTP请求的Session、线程、Socket连接等对象，这类对象跟业务挂钩，因此生命周期长，还有一部分是运行过程汇总生成的临时变量，这些对象生命周期短，比如：String,这些对象甚至<strong>只使用一次即可回收</strong></p><p>目前所有GC都采用分代收集算法进行执行<br>对象的状态经过大量的调研研究划分为年青代与老年代两个类别<br><strong>年青代</strong>：区域相对小，对象生命周期短、存活率低，且产生应用频繁<br>复制算法回收整理速度是最快的。复制算法效率只与当前存活对象大小有关，因此很实用与年青代的回收，而空间问题，因为存活率问题，所以单独开辟S0,S1两块空间处理清除后结果<br><strong>老年代</strong>：区域较大，生命周期长、存活率高，回收不及年青代频繁<br>这种情况存在大量存过对象下，复制不适用，所以一般是用清除与整理算法混合实现<br>Mark阶段的开销与存活对象的数量成正比<br>Sweep阶段的开销与所管理的大小成正比<br>Compact阶段的开销与存活对象的数据成正比</p><p><strong>增量收集算法</strong></p><p>上述所有算法，在垃圾回收过程中，软件都会处于一种Stop The World的状态。在STW状态下，应用程序所有线程都会挂起，暂停一切正常工作，等待垃圾回收完成，这种情况将严重影响用户体验或系统稳定。为了解决这个问题，催生出了一套增量手机算法。</p><p>基本概念：<br>如果一次性将所有垃圾进行处理，需要造成系统长时间停顿，那么久可以让垃圾收集线程和应用程序线程交替执行。每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。一次反复，直到垃圾收集完成。</p><p>总结：实际上就是通过对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理、复制等工作。</p><p>使用这种方式，由于在垃圾回收过程中，间断性的还执行了应用程序代码，所以能减少停顿时间。但是因为线程切换和上下文转换的消耗，会是的垃圾回收的总体成本上升，系统吞吐量下降。</p><p><strong>分区算法</strong></p><img src="/2022/11/18/GC及调优/image-20221118194234450.png" title="[GC及调优]"><p>相同条件下，堆空间越大，一次GC时间越长，停顿时间也越长，为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。</p><p><strong>总结 :注意，实际上GC过程要复杂的多，需要考虑的不单单是这些，还有并行与并发的兼顾，而且通常都会应用复合算法去使用</strong></p><h4 id="垃圾回收器与内存管理"><a href="#垃圾回收器与内存管理" class="headerlink" title="垃圾回收器与内存管理"></a><strong>垃圾回收器与内存管理</strong></h4><p>常用7种垃圾回收器</p><img src="/2022/11/18/GC及调优/image-20221118194343343.png" title="[GC及调优]"><p><strong>垃圾回收的并行与串行</strong></p><p>并行&amp;串行：<br><strong>并行</strong>（Parallel）：只多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。<br>ParNew、Parallel Scavenge、Parallel Old<br><strong>串行</strong>（Serial）：<br>单线程执行<br>如果内存不够则程序暂停，启动JVM垃圾回收器进行垃圾回收。回收万再启动城西县城</p><img src="/2022/11/18/GC及调优/image-20221118194424868.png" title="[GC及调优]"><img src="/2022/11/18/GC及调优/image-20221118194433609.png" title="[GC及调优]"><p>并行&amp;并发：<br><strong>并发</strong>：指的是多个事情在同一时间段内同时发生<br>并发的多个任务之间是相互抢占资源<br><strong>并行</strong>：指的是多个事情在同一时间点上同时发生了<br>并行的多个线程之间不相互抢占资源</p><p>只有在<strong>多个CPU</strong>或者<strong>一个CPU多核</strong>的情况中，才会发生并行。<br>否则，看似相同发生的事情，实际上都是并发执行</p><p>常用GC垃圾回收器对比</p><img src="/2022/11/18/GC及调优/image-20221118194745187.png" title="[GC及调优]"><p><strong>CMS回收器</strong></p><img src="/2022/11/18/GC及调优/image-20221118194800255.png" title="[GC及调优]"><p>初始标记：<br>这个阶段会出现STW现象，主要工作内容是标记处GCRoot能关联到的对象。（注意，这里只有GCROOT的对象，不会涉及引用链）<br>并发标记：<br>遍历GCROOT整个引用链，这个工作耗时非常长，采取了与垃圾收集器线程一起运行的方案<br>重新标记：<br>因为在上面步骤有用户线程行为，所以此处再次STW，进行重新标记，但是这部分只管重新运行后的那部分对象数据的变动。<br>并发清理：<br>清理所有标记的死亡对象，释放，这一步与用户线程同步进行<br>并发重置：</p><img src="/2022/11/18/GC及调优/image-20221118194826422.png" title="[GC及调优]"><p><strong>评估GC的性能指标</strong></p><p><strong>吞吐量</strong>：运行用户代码的时间占总运行时间的比例<br>                 总运行时间=程序运行时间+内存回收时间<br><strong>垃圾收集开销</strong>：吞吐量的补数，垃圾收集所用时间与总运行时间的比例<br><strong>暂停时间</strong>：执行垃圾收集时，程序的工作线程被暂停的时间<br><strong>收集频率</strong>：应用程序的执行，收集操作发生的次数<br><strong>内存占用</strong>：java堆区所占的内存大小</p><p><strong>不可达三角</strong>：<br>    性能调优的终极概念：空间换时间、时间换空间<br>不存在完美，一般情况下抓住吞吐量与暂停时间来设计</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;GC核心概述&quot;&gt;&lt;a href=&quot;#GC核心概述&quot; class=&quot;headerlink&quot; title=&quot;GC核心概述&quot;&gt;&lt;/a&gt;&lt;strong&gt;GC核心概述&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;Java自动化内存管理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;好
      
    
    </summary>
    
    
      <category term="JVM" scheme="http://www.yppcat.top/tags/JVM/"/>
    
  </entry>
  
</feed>
